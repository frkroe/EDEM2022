{"cells":[{"cell_type":"markdown","metadata":{"id":"BNkZfzfxGZ0z"},"source":["# DataFrames Basics Exercises"]},{"cell_type":"markdown","metadata":{"id":"AQieQ5pkGfNm"},"source":["## Prerrequisites"]},{"cell_type":"markdown","metadata":{"id":"HelxRmCPGpql"},"source":["Install Spark and Java in VM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Cn3c-ywGtDV"},"outputs":[],"source":["# install Java8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","# download spark3.0.1\n","!wget -q https://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop2.tgz"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1670456814523,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"D95sNcJfGvyV","outputId":"e94044e3-ef55-433c-dfb0-fd86557ffb97"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 267684\n","drwxr-xr-x 1 root root      4096 Dec  6 14:35 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n","-rw-r--r-- 1 root root 274099817 Oct 15 10:53 spark-3.3.1-bin-hadoop2.tgz\n"]}],"source":["ls -l # check the .tgz is there"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qtBMGi7EGvwN"},"outputs":[],"source":["# unzip it\n","!tar xf spark-3.3.1-bin-hadoop2.tgz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6JO331NrGvtt"},"outputs":[],"source":["!pip install -q findspark"]},{"cell_type":"markdown","metadata":{"id":"02epIDkbG24d"},"source":["Defining the environment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmON5zHJG4-m"},"outputs":[],"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop2\"\n","os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[*] pyspark-shell\""]},{"cell_type":"markdown","metadata":{"id":"WgvNJQOAGZ00"},"source":["Start Spark Session\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":9230,"status":"ok","timestamp":1670456831312,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"siaPZq4XGZ00","outputId":"6ca941e7-feed-4609-c602-178830155d2c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'3.3.1'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import findspark\n","findspark.init(\"spark-3.3.1-bin-hadoop2\")# SPARK_HOME\n","\n","from pyspark.sql import SparkSession\n","\n","# create the session\n","spark = SparkSession \\\n","        .builder \\\n","        .appName(\"DataFramesBasics Exercises\") \\\n","        .master(\"local[*]\") \\\n","        .getOrCreate()\n","\n","spark.version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"elapsed":2301,"status":"ok","timestamp":1670445013413,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"},"user_tz":-60},"id":"nsBkpLh6GZ01","outputId":"566b7993-0fe2-4352-cb0c-c0b45b96cdad"},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://bae4ada9eee7:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Introductory Exercises</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f14fe863c10>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bqu4fQnNGZ02"},"outputs":[],"source":["# For Pandas conversion optimization\n","spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9DDmYQKGZ02"},"outputs":[],"source":["# Import sql functions\n","from pyspark.sql.functions import *"]},{"cell_type":"markdown","metadata":{"id":"NYrtXWZIHKMt"},"source":["Download datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2lkKBm3CHL-l"},"outputs":[],"source":["!mkdir -p dataset\n","!wget -q https://raw.githubusercontent.com/paponsro/spark_edem_2022/master/datasets/movies.json -P /dataset\n","!wget -q https://raw.githubusercontent.com/paponsro/spark_edem_2022/master/datasets/cars.json -P /dataset"]},{"cell_type":"markdown","metadata":{"id":"sxWVtHu5GZ02"},"source":["## DataFrames Basics Exercises"]},{"cell_type":"markdown","metadata":{"id":"rZt5nAVLRmeF"},"source":["1) Create a manual DF describing smartphones\n","  - maker\n","  - model\n","  - screen dimension\n","  - camera megapixels\n","  \n","2) Read another file from the dataset/ folder, e.g. movies.json\n","  - print its schema\n","  - count the number of rows, call count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DF-WHVfjRq49"},"outputs":[],"source":["# 1)\n","schema = \"`maker` STRING NOT NULL, `model` STRING NOT NULL, `screen dimension` FLOAT NOT NULL, `camera megapixels` INTEGER NOT NULL\"\n","data = [(\"abc\", \"123\", 32.3, 48), \n","        (\"cdv\", \"194\", 25.3, 18)\n","        ]\n","df = spark.createDataFrame(data, schema)\n","df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 2)\n","df2 = spark.read.json(\"/dataset/movies.json\")\n","df2.printSchema()\n","print(f'number of rows: {df2.count()}')"]},{"cell_type":"markdown","metadata":{"id":"99pcX8w3SVdO"},"source":["## Columns and Expressions Exercises"]},{"cell_type":"markdown","metadata":{"id":"Q4LymMG0Sg_l"},"source":["1. Read the movies DF and select 2 columns of your choice\n","2. Create another column summing up the total profit of the movies = US_Gross + Worldwide_Gross + DVD sales. Are you pbtaining nulls? How you can solve it?\n","3. Select all COMEDY movies with IMDB rating above 6\n","\n","Use as many versions as possible"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 1)\n","df_movies = spark.read.json(\"/dataset/movies.json\")\n","df_movies.select(\"Director\",\"Title\").show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 2)\n","df_movies \\\n",".na.fill(value=0,subset=[\"US_Gross\", \"Worldwide_Gross\", \"US_DVD_Sales\"]) \\\n",".withColumn(\"Total Profit\",col(\"US_Gross\")+col(\"Worldwide_Gross\")+ col(\"US_DVD_Sales\")) \\\n",".select(\"Title\", \"Total Profit\").show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 3)\n","df_movies.filter((col(\"Major_Genre\") == 'Comedy') & (col('IMDB_Rating') > 6)).show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 3) alternativa\n","df_movies.filter(\"Major_Genre == 'Comedy' and IMDB_Rating > 6\").show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.12","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f167d7208f068a761a61c7abe8a19a71cbf6c597593c47696850f64e310bbdac"}}},"nbformat":4,"nbformat_minor":0}
