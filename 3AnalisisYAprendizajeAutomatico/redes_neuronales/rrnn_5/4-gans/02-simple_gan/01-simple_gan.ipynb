{"cells":[{"cell_type":"markdown","metadata":{"id":"7sNYcxkuODur"},"source":["<font color=\"#CA0032\"><h1 align=\"left\">**Redes Generativas Adversariales (GANs)**</h1></font>\n","\n","<font color=\"#6E6E6E\"><h1 align=\"left\">**Creación de imágenes nuevas con GANs no profundas**</h1></font>\n","\n","<h2 align=\"left\">Manuel Sánchez-Montañés</h2>\n","\n","<font color=\"#6E6E6E\"><h2 align=\"left\">manuel.smontanes@gmail.com</h2></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3BLGUiGQ5tF"},"outputs":[],"source":["COLAB                  = True\n","SAVE_INTERMEDIATE_DATA = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6BqoWI9zN5FE"},"outputs":[],"source":["import os\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","from keras.layers import Input\n","from keras.models import Model, Sequential\n","from keras.layers.core import Reshape, Dense, Dropout, Flatten\n","from keras.layers import LeakyReLU, BatchNormalization\n","from keras.datasets import mnist\n","from keras.optimizers import Adam\n","from keras import backend as K\n","from keras import initializers\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fxu4rn0dN5FO"},"outputs":[],"source":["np.random.seed(1000)\n","\n","# Tamaño del espacio latente\n","randomDim = 20\n","\n","# Carga de datos\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = X_train.astype(np.float32) / 255 # para que esté entre 0 y 1\n","X_train = 2*X_train - 1 # para que esté entre -1 y 1\n","X_train = X_train.reshape(-1, 28*28)\n","\n","X_train = X_train[y_train>=5] # para simplificar se entrena sólo con los dígitos 5,6,7,8,9\n","y_train = y_train[y_train>=5] # ídem"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8QTW34M2XwIj"},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OV_FnQrtcMGs"},"outputs":[],"source":["X_train.min(), X_train.max()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-4tIH6viVnoT"},"outputs":[],"source":["ind = 100\n","plt.figure(figsize=(3,3))\n","plt.imshow(X_train[ind].reshape(28,28), cmap=\"gray\")\n","plt.title(\"Clase {}\".format(y_train[ind]));"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o5VSz99WHkbG"},"outputs":[],"source":["ind = 202\n","plt.figure(figsize=(3,3))\n","plt.imshow(X_train[ind].reshape(28,28), cmap=\"gray\")\n","plt.title(\"Clase {}\".format(y_train[ind]));"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uvXAfkZeWbVf"},"outputs":[],"source":["ind = 20000\n","plt.figure(figsize=(3,3))\n","plt.imshow(X_train[ind].reshape(28,28), cmap=\"gray\")\n","plt.title(\"Clase {}\".format(y_train[ind]));"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L5vPh1NhV6ho"},"outputs":[],"source":["X_train.shape"]},{"cell_type":"markdown","metadata":{"id":"KdqGj4HSO_Y5"},"source":["**Optimizadores**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Twlq6G2pO9qe"},"outputs":[],"source":["# optimizador para el generador:\n","adam_gen  = Adam(lr=0.0002, beta_1=0.5) # lr por defecto: 0.001\n","\n","# optimizador para el discriminador:\n","adam_disc = Adam(lr=0.0002/2, beta_1=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QQtpRtfsehnp"},"outputs":[],"source":["X_train.shape"]},{"cell_type":"markdown","metadata":{"id":"Bs9EsDOjPDqZ"},"source":["**Red generadora (\"generator\")**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31cuT568WXqj"},"outputs":[],"source":["randomDim # tamaño del espacio latente"]},{"cell_type":"markdown","metadata":{"id":"erPrJJpX9WPk"},"source":["Función de activación estándar en Deep Learning: ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWLNcvDkVQg7"},"outputs":[],"source":["def relu(z): # definición \"a mano\"\n","    return z*(z>0)\n","\n","z = np.linspace(-10,10,100) # genero array de 100 puntos que recorren intervalo entre -10 y 10\n","plt.plot(z, relu(z))\n","plt.title(\"ReLU\");"]},{"cell_type":"markdown","metadata":{"id":"KmN_CyEL9tsS"},"source":["Función de activación en GANs: Leaky ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCs33h_rVQlc"},"outputs":[],"source":["def leakyrelu(z):\n","    return z*(z>0) - 0.2*np.abs(z)*(z<0)\n","\n","z = np.linspace(-10,10,100)\n","plt.plot(z, leakyrelu(z))\n","plt.title(\"Leaky ReLU\");"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPrDpI7SN5FW"},"outputs":[],"source":["# entrada: randomDim dimensiones\n","# salida:  784 valores (entre -1 y 1)\n","#\n","# Función de activación estándar en DL:\n","# ReLU(x): max(0,x)\n","# En GANs:\n","# LeakyReLU(x,0.2):\n","#     si x>0: salida = x\n","#     si x<0: salida = 0.2*x = -0.2*abs(x)\n","\n","generator = Sequential()\n","generator.add(Dense(64,input_shape=randomDim))    # input_dim = tamaño de la entrada / del espacio latente\n","generator.add(LeakyReLU(0.2))                     # función de activación\n","generator.add(Dense(784, activation='tanh'))      # tanh: tangente hiperbólica\n","generator.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2FjTuwAaxax"},"outputs":[],"source":["type( (20) ), type( (20,))"]},{"cell_type":"markdown","metadata":{"id":"kl9GwhKDPKCM"},"source":["**Red discriminadora (\"discriminator\")**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wXC398GPVhv7"},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBl2P8wTPKTZ"},"outputs":[],"source":["discriminator = Sequential()\n","\n","# Definir entrada de la red\n","discriminator.add(Dense(64, input_shape=(784,)))     # entrada: 784 valores (entre -1 y 1); 784 = 28*28\n","discriminator.add(LeakyReLU(0.2))                    # función de activación\n","discriminator.add(Dropout(0.3))                      # dropout: 30% de neuronas se desactivan aleatoriamente\n","'''# Definir capas ocultas (aqui quitado por tener un modelo más simple y rapido)\n","discriminator.add(Dense(16))                         # capa oculta\n","discriminator.add(LeakyReLU(0.2))                    # función de activación\n","discriminator.add(Dropout(0.3))                      # dropout: 30% de neuronas se desactivan aleatoriamente'''\n","# Definir salida de la red (si es falsa o verdadera = 1)\n","discriminator.add(Dense(1, activation='sigmoid'))    # salida: 1 valor (entre 0 y 1)\n","# Compilar la red\n","discriminator.compile(loss='binary_crossentropy',    # función de pérdida\n","                      optimizer=adam_disc)           # optimizador\n","discriminator.summary()"]},{"cell_type":"markdown","metadata":{"id":"RcsP01BnPf0K"},"source":["**Sistema combinado (GAN) generador+discriminador congelado**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_finHCNPf-1"},"outputs":[],"source":["# completar\n","discriminator.trainable = False                 # congelo discriminador;  para que no se entrene el discriminador\n","ganInput = Input(shape=(randomDim,))            # entrada: espacio latente\n","ganOutput = discriminator(generator(ganInput))  # salida: discriminador de la salida del generador\n","\n","gan = Model(inputs=ganInput, outputs=ganOutput) # modelo: entrada = espacio latente; salida = discriminador de la salida del generador\n","gan.compile(loss='binary_crossentropy',         # función de pérdida\n","            optimizer=adam_gen)                  # optimizador del generador porque es el que se entrena\n","gan.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EqRfCbGwN5Fb"},"outputs":[],"source":["# Plot the loss from each batch\n","def plotLoss(epoch):\n","    plt.figure(figsize=(10, 3))\n","    plt.plot(range(1,len(dLosses)+1), dLosses,\n","             label='Discriminitive loss', linewidth=3)\n","    plt.plot(range(1,len(gLosses)+1), gLosses,\n","             label='Generative loss', linewidth=3)\n","    plt.xlabel('Epoch', fontsize=16)\n","    plt.ylabel('Loss', fontsize=16)\n","    plt.legend(fontsize=14)\n","    if not COLAB:\n","        plt.savefig('./images/gan_loss_epoch_{}.png'.format(epoch))\n","    plt.show()\n","\n","# Create a wall of generated images\n","def plotGeneratedImages(epoch, examples=100,\n","                        dim=(10, 10), figsize=(10, 10)):\n","    noise = np.random.normal(0, 1, size=[examples, randomDim])\n","    generatedImages = generator.predict(noise)\n","    generatedImages = generatedImages.reshape(examples, 28, 28)\n","\n","    plt.figure(figsize=figsize)\n","    for i in range(len(generatedImages)):\n","        plt.subplot(dim[0], dim[1], i+1)\n","        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n","        plt.axis('off')\n","    plt.tight_layout()\n","    if SAVE_INTERMEDIATE_DATA:\n","        plt.savefig('./images/gan_generated_image_epoch_{}.png'.format(epoch))\n","    plt.show()\n","\n","\n","def plotImages(images, nrows, ncols, figsize):\n","    plt.figure(figsize=figsize)\n","    for i in range(images.shape[0]):\n","        plt.subplot(nrows, ncols, i+1)\n","        plt.imshow(images[i].reshape(28,28), interpolation='nearest', cmap='gray_r')\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","\n","    \n","# Save the generator and discriminator networks (and weights) for later use\n","def saveModels(epoch):\n","    generator.save('./models/gan_generator_epoch_{}.h5'.format(epoch))\n","    discriminator.save('./models/gan_discriminator_epoch_{}.h5'.format(epoch))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhhPnulASOeH"},"outputs":[],"source":["if SAVE_INTERMEDIATE_DATA:\n","    os.makedirs(\"./images\", exist_ok=True)\n","    os.makedirs(\"./models\", exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q29r1d5oU77j"},"outputs":[],"source":["len(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TY8Ts86-PsBh"},"outputs":[],"source":["dLosses = [] # histórico de los valores de la función de coste del discriminador\n","gLosses = [] # histórico de los valores de la función de coste del generador"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WY3TCvoT_VUs"},"outputs":[],"source":["epochs = 200\n","batchSize=128\n","\n","batchCount = len(X_train) // batchSize\n","batchCount"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IbBa1I9aJVCb"},"outputs":[],"source":["batchSize*[0.9] + batchSize*[0.1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mqk9uV_9N5Fi"},"outputs":[],"source":["print('Epochs:', epochs)\n","print('Batch size:', batchSize)\n","print('Batches per epoch:', batchCount)\n","\n","for e in range(1, epochs+1):\n","    print('-'*15, 'Epoch %d' % e, '-'*15)\n","    for _ in tqdm(range(batchCount)):\n","\n","        # ** EMPIEZA MINI-ENTRENAMIENTO DISCRIMINADOR: **\n","        \n","        # Genero entrada aleatoria al generador para batchSize (128) imágenes:\n","        noise = np.random.normal(0, 1, size=[batchSize, randomDim]) # distribución Gaussiana de media 0 y std 1\n","        \n","        # Genero imágenes falsas a través del generator:\n","        generatedImages = generator.predict(noise)\n","\n","        # Selecciono al azar batchSize (128) imágenes reales\n","        imageBatch = X_train[np.random.randint(0, len(X_train), size=batchSize)]\n","\n","        # Genero un X donde las 128 primeras imágenes son reales y las 128 siguientes fake\n","        X = np.concatenate([imageBatch, generatedImages])\n","        \n","        # Genero las etiquetas para estas 128+128 imágenes:\n","        # 128 \"casi unos\" (clase \"real\") seguidos de 128 \"casi ceros\" (clase \"fake\")\n","        yDis = np.array(batchSize*[0.9] + batchSize*[0.1])\n","        \n","        # Descongelo el discriminador:\n","        discriminator.trainable = True\n","\n","        # Entreno discriminador\n","        dloss = discriminator.train_on_batch(X, yDis)\n","        \n","        # ** TERMINA MINI-ENTRENAMIENTO DISCRIMINADOR **\n","\n","        \n","           \n","        # ** EMPIEZA MINI-ENTRENAMIENTO GENERADOR: **\n","        \n","        # Genero randomDim variables latentes (ruido) de entrada al generador\n","        # por cada una de las batchSize imágenes que quiero generar:\n","        noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n","\n","        # Genero etiquetas que deseo que el discriminador genere al pasarle\n","        # las imágenes creadas por el generador (deseo engañarle, con lo que\n","        # la salida deseada es 0.9, \"casi real\")\n","        yGen = np.array(batchSize*[0.9])\n","\n","        # Congelo el discriminador (en este paso solo aprende el generador):\n","        discriminator.trainable = False\n","\n","        # Entreno el sistema (en realidad solo se entrena el generador ya que\n","        # he congelado el discriminador):\n","        gloss = gan.train_on_batch(noise, yGen)\n","\n","        # ** TERMINA MINI-ENTRENAMIENTO GENERADOR **\n","\n","\n","    # Store loss of most recent batch from this epoch\n","    dLosses.append(dloss)\n","    gLosses.append(gloss)\n","    \n","    if (e==1) or ((e%5)==0):\n","        plotGeneratedImages(e)\n","        if SAVE_INTERMEDIATE_DATA:\n","            saveModels(e)\n","    if (e%5)==0:\n","        plotLoss(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PyjqZEVUN5Fo"},"outputs":[],"source":["# Plot losses from every epoch\n","plotLoss(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UH4KJHAJN5Fs"},"outputs":[],"source":["plotGeneratedImages(e+1)"]},{"cell_type":"markdown","metadata":{"id":"-lVfmd7fom8_"},"source":["Ahora generamos un conjunto de vectores de entrada a la GAN. Cada vector de entrada tiene **randomDim** componentes:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5yt0ADPqkmz"},"outputs":[],"source":["randomDim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_5ol_-eN5Fw"},"outputs":[],"source":["# Vamos a mostrar los resultados obtenidos para el conjunto de vectores\n","# de entrada en una matriz de nfilas * ncols:\n","nfilas = 20\n","ncols  = 20\n","\n","# Inicializo a 0 el conjunto de vectores de entrada a la GAN:\n","input0 = np.zeros((nfilas*ncols, randomDim))\n","\n","# Termino de calcular el conjunto de vectores de entrada.\n","# La idea es que en cada fila las componentes diferentes de cero\n","# son las mismas, y sus valores cambian de columna a columna:\n","\n","nvector = 0\n","for i in range(nfilas):\n","    # Qué componentes de las randomDim se van a perturbar:\n","    componentes_pert = range(i,i+1)\n","    for j,x in enumerate(np.linspace(-4, 4, ncols)):\n","        input_id = i+0\n","        input0[nvector][componentes_pert] = x\n","        nvector = nvector + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nvjGlI9tN5F1"},"outputs":[],"source":["generatedImages = generator.predict(input0)\n","plotImages(generatedImages, nfilas, ncols, figsize=(14,14))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8tSb5QfN5F5"},"outputs":[],"source":["generatedImages.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQZ1_D1oN5F-"},"outputs":[],"source":["# Para grabar las redes a fichero:\n","\n","generator.save(\"./generator.h5\")\n","generator.save_weights(\"./generator_weights.h5\")\n","discriminator.save(\"./discriminator.h5\")\n","discriminator.save_weights(\"./discriminator_weights.h5\")\n","gan.save(\"./gan.h5\")\n","gan.save_weights(\"./gan_weights.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u9hlWmhD8kIO"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":0}
