{"cells":[{"cell_type":"markdown","metadata":{"id":"szsImiPr1ftc"},"source":["<font color=\"#CA0032\"><h1 align=\"left\">**Redes Generativas Adversariales (GANs)**</h1></font>\n","\n","<font color=\"#6E6E6E\"><h1 align=\"left\">**Creación de imágenes nuevas con GANs Convolucionales Profundas (DC-GANs)**</h1></font>\n","\n","<h2 align=\"left\">Manuel Sánchez-Montañés</h2>\n","\n","<font color=\"#6E6E6E\"><h2 align=\"left\">manuel.smontanes@gmail.com</h2></font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPPx0ntx10Bn"},"outputs":[],"source":["COLAB                  = True\n","SAVE_INTERMEDIATE_DATA = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4F_QPwSSeEgZ"},"outputs":[],"source":["import os\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn\n","\n","from keras.layers import Input\n","from keras.models import Model, Sequential\n","from keras.layers.core import Reshape, Dense, Dropout, Flatten\n","from keras.layers import LeakyReLU\n","from keras.layers.convolutional import Conv2D, UpSampling2D\n","from keras.datasets import mnist\n","from keras.optimizers import Adam\n","from keras import backend as K\n","from keras import initializers\n","\n","np.random.seed(1000)\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhnrHl1PeEg2"},"outputs":[],"source":["# Tamaño del espacio latente\n","randomDim = 20\n","\n","# Carga de datos\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = X_train.astype(np.float32) / 255 # para que esté entre 0 y 1\n","X_train = 2*X_train - 1 # para que esté entre -1 y 1\n","print(X_train.shape)\n","\n","X_train = X_train.reshape(X_train.shape + (1,))\n","print(X_train.shape)\n","\n","X_train = X_train[y_train>=5] # para simplificar se entrena sólo con las clases 5,6,7,8,9\n","y_train = y_train[y_train>=5] # ídem"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KjZb5nEHeEhG"},"outputs":[],"source":["X_train.shape"]},{"cell_type":"markdown","metadata":{"id":"1xdgmXr62thq"},"source":["**Optimizadores**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hIsftPV82rl6"},"outputs":[],"source":["# optimizador para el generador:\n","adam_gen  = Adam(lr=0.0002, beta_1=0.5) # lr por defecto: 0.001\n","\n","# optimizador para el discriminador:\n","adam_disc = Adam(lr=0.0002/2, beta_1=0.5)"]},{"cell_type":"markdown","metadata":{"id":"bGNHbHCu2660"},"source":["**Red generadora (\"generator\")**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3hmRCy3pr7H"},"outputs":[],"source":["randomDim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nkq1LIX6F3ur"},"outputs":[],"source":["# UpSampling2D\n","# Toma:\n","\n","#  1 5 3\n","#  8 9 2\n","#  0 1 0\n","\n","# Devuelve:\n","\n","#  1 1 5 5 3 3\n","#  1 1 5 5 3 3\n","#  8 8 9 9 2 2\n","#  8 8 9 9 2 2\n","#  0 0 1 1 0 0\n","#  0 0 1 1 0 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1oouFrZeEhO"},"outputs":[],"source":["generator = Sequential()\n","\n","# completar\n","generator.add(Dense(64,input_shape=randomDim))    # input_dim = tamaño de la entrada / del espacio latente\n","generator.add(LeakyReLU(0.2))                     # función de activación es LeakyReLU (RELU tiende apagar neuronas por eso no se usa)\n","generator.add(Dense(784, activation='tanh'))      # tanh: tangente hiperbólica\n","\n","generator.summary()"]},{"cell_type":"markdown","metadata":{"id":"x-jRmYr23CIg"},"source":["**Discriminador**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jd3RpWaorqdD"},"outputs":[],"source":["from keras.layers import MaxPool2D"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qqvUxGZR_sCM"},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1T1QwPzeEhS"},"outputs":[],"source":["discriminator = Sequential()\n","\n","# completar\n","discriminator.add(Dense(64, input_shape=(784,)))     # entrada: 784 valores (entre -1 y 1); 784 = 28*28\n","discriminator.add(LeakyReLU(0.2))                    # función de activación\n","discriminator.add(Dropout(0.3))                      # dropout: 30% de neuronas se desactivan aleatoriamente\n","discriminator.add(Dense(1, activation='sigmoid'))    # salida: 1 valor (entre 0 y 1)\n","discriminator.compile(loss='binary_crossentropy',    # función de pérdida\n","                      optimizer=adam_disc)           # optimizador\n","\n","discriminator.summary()"]},{"cell_type":"markdown","metadata":{"id":"JxvFEIb83Gkr"},"source":["**Red combinada (sistema GAN)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6yomJ0RGeEhY"},"outputs":[],"source":["# completar\n","discriminator.trainable = False                 # congelo discriminador;  para que no se entrene el discriminador\n","ganInput = Input(shape=(randomDim,))            # entrada: espacio latente\n","ganOutput = discriminator(generator(ganInput))  # salida: discriminador de la salida del generador\n","\n","gan = Model(inputs=ganInput, outputs=ganOutput) # modelo: entrada = espacio latente; salida = discriminador de la salida del generador\n","gan.compile(loss='binary_crossentropy',         # función de pérdida\n","            optimizer=adam_gen)                  # optimizador del generador porque es el que se entrena\n","\n","gan.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRGDFvIyeEhc"},"outputs":[],"source":["# Plot the loss from each batch\n","def plotLoss(epoch):\n","    plt.figure(figsize=(10, 3))\n","    plt.plot(range(1,len(dLosses)+1), dLosses,\n","             label='Discriminitive loss', linewidth=3)\n","    plt.plot(range(1,len(gLosses)+1), gLosses,\n","             label='Generative loss', linewidth=3)\n","    plt.xlabel('Epoch', fontsize=16)\n","    plt.ylabel('Loss', fontsize=16)\n","    plt.legend(fontsize=14)\n","    if not COLAB:\n","        plt.savefig('./images/dcgan_loss_epoch_{}.png'.format(epoch))\n","    plt.show()\n","\n","# Create a wall of generated images\n","def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n","    noise = np.random.normal(0, 1, size=[examples, randomDim])\n","    generatedImages = generator.predict(noise)\n","\n","    plt.figure(figsize=figsize)\n","    for i in range(generatedImages.shape[0]):\n","        plt.subplot(dim[0], dim[1], i+1)\n","#        plt.imshow(generatedImages[i, 0], interpolation='nearest', cmap='gray_r')\n","        plt.imshow(generatedImages[i,:,:,0], interpolation='nearest', cmap='gray_r')\n","        plt.axis('off')\n","    plt.tight_layout()\n","    if SAVE_INTERMEDIATE_DATA:\n","        plt.savefig('./images/dcgan_generated_image_epoch_{}.png'.format(epoch))\n","    plt.show()\n","\n","    \n","def plotImages(images, nrows, ncols, figsize):\n","    plt.figure(figsize=figsize)\n","    for i in range(images.shape[0]):\n","        plt.subplot(nrows, ncols, i+1)\n","        plt.imshow(images[i,:,:,0], interpolation='nearest', cmap='gray_r')\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","    \n","\n","# Save the generator and discriminator networks (and weights) for later use\n","def saveModels(epoch):\n","    generator.save('models/dcgan_generator_epoch_{}.h5'.format(epoch))\n","    discriminator.save('models/dcgan_discriminator_epoch_{}.h5'.format(epoch))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"geLX4Nlt3aXg"},"outputs":[],"source":["if SAVE_INTERMEDIATE_DATA:\n","    os.makedirs(\"./images\", exist_ok=True)\n","    os.makedirs(\"./models\", exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AWQLyh8m3OQW"},"outputs":[],"source":["dLosses = [] # histórico de los valores de la función de coste del discriminador\n","gLosses = [] # histórico de los valores de la función de coste del generador"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XS0eBY9feEhh"},"outputs":[],"source":["epochs=50\n","batchSize=128\n","epocas_refrescar_grafica=1\n","\n","batchCount = len(X_train) // batchSize\n","print('Epochs:', epochs)\n","print('Batch size:', batchSize)\n","print('Batches per epoch:', batchCount)\n","\n","for e in range(1, epochs+1):\n","    print('-'*15, 'Epoch %d' % e, '-'*15)\n","    for _ in tqdm(range(batchCount)):\n","\n","        # ** EMPIEZA MINI-ENTRENAMIENTO DISCRIMINADOR: **\n","        \n","        # Genero entrada aleatoria al generador para batchSize (128) imágenes:\n","        noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n","\n","        # Genero imágenes falsas a través del generator:\n","        generatedImages = generator.predict(noise)\n","\n","        # Selecciono al azar batchSize (128) imágenes reales\n","        imageBatch = X_train[np.random.randint(0, len(X_train), size=batchSize)]\n","        \n","        # Genero un X donde las 128 primeras imágenes son reales y las 128 siguientes fake\n","        X = np.concatenate([imageBatch, generatedImages])\n","        \n","        # Genero las etiquetas para estas 128+128 imágenes:\n","        # 128 \"casi unos\" (clase \"real\") seguidos de 128 \"casi ceros\" (clase \"fake\")\n","        yDis = np.array(batchSize*[0.9] + batchSize*[0.1])\n","        \n","        # Descongelo el discriminador:\n","        discriminator.trainable = True\n","\n","        # Entreno discriminador\n","        dloss = discriminator.train_on_batch(X, yDis)\n","\n","        # ** TERMINA MINI-ENTRENAMIENTO DISCRIMINADOR **\n","\n","\n","        # ** EMPIEZA MINI-ENTRENAMIENTO GENERADOR: **\n","        \n","        # Genero randomDim variables latentes (ruido) de entrada al generador\n","        # por cada una de las batchSize imágenes que quiero generar:\n","        noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n","\n","        # Genero etiquetas que deseo que el discriminador genere al pasarle\n","        # las imágenes creadas por el generador (deseo engañarle, con lo que\n","        # la salida deseada es 0.9, \"casi real\")\n","        yGen = np.array(batchSize*[0.9])\n","\n","        # Congelo el discriminador (en este paso solo aprende el generador):\n","        discriminator.trainable = False\n","\n","        # Entreno el sistema (en realidad solo se entrena el generador ya que\n","        # he congelado el discriminador):\n","        gloss = gan.train_on_batch(noise, yGen)\n","\n","        # ** TERMINA MINI-ENTRENAMIENTO GENERADOR **\n","        \n","        \n","    # Store loss of most recent batch from this epoch\n","    dLosses.append(dloss)\n","    gLosses.append(gloss)\n","    \n","    if (e==1) or ((e%epocas_refrescar_grafica)==0):\n","        plotGeneratedImages(e)\n","        if SAVE_INTERMEDIATE_DATA:\n","            saveModels(e)\n","    if (e%epocas_refrescar_grafica)==0:\n","        plotLoss(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJ2ohlD9eEhl"},"outputs":[],"source":["# Plot losses from every epoch\n","plotLoss(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3l1ZjfXeEhu"},"outputs":[],"source":["# Generación de 100 imágenes nuevas:\n","\n","n_imagenes = 100\n","\n","noise = np.random.normal(0, 1, size=[n_imagenes, randomDim])\n","generatedImages = generator.predict(noise)\n","plotGeneratedImages(e+1)"]},{"cell_type":"markdown","metadata":{"id":"jEEq1l9Cv67X"},"source":["Ahora generamos un conjunto de vectores de entrada a la GAN. Cada vector de entrada tiene **randomDim** componentes:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zyF3Mz2ieEhy"},"outputs":[],"source":["nrows = 5\n","ncols = 10\n","input0 = np.zeros((nrows*ncols, randomDim))\n","caso = 0\n","for i in range(nrows):\n","    for j in range(ncols):\n","        input_id = i+10\n","        input0[caso,input_id] = -2+4*j/(ncols-1)\n","        caso = caso + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yrr4a5pbv_Ne"},"outputs":[],"source":["# Vamos a mostrar los resultados obtenidos para el conjunto de vectores\n","# de entrada en una matriz de nfilas * ncols:\n","nfilas = 5\n","ncols  = 10\n","\n","# Inicializo a 0 el conjunto de vectores de entrada a la GAN:\n","input0 = np.zeros((nfilas*ncols, randomDim))\n","\n","# Termino de calcular el conjunto de vectores de entrada.\n","# La idea es que en cada fila las componentes diferentes de cero\n","# son las mismas, y sus valores cambian de columna a columna:\n","\n","nvector = 0\n","for i in range(nfilas):\n","    # Qué componentes de las randomDim se van a perturbar:\n","    componentes_pert = range(15+i,15+i+1)\n","    for j,x in enumerate(np.linspace(-2, 2, ncols)):\n","        input_id = i+0\n","        input0[nvector][componentes_pert] = x\n","        nvector = nvector + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKxMt1EbeEh1"},"outputs":[],"source":["generatedImages = generator.predict(input0)\n","plotImages(generatedImages, nfilas, ncols, figsize=(14,7))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dl37RjuaeEh4"},"outputs":[],"source":["generatedImages.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XLM23UUpeEhq"},"outputs":[],"source":["# Para grabar las redes a fichero:\n","\n","generator.save(\"./dcgan_generator.h5\")\n","generator.save_weights(\"./dcgan_generator_weights.h5\")\n","discriminator.save(\"./dcgan_discriminator.h5\")\n","discriminator.save_weights(\"./dcgan_discriminator_weights.h5\")\n","gan.save(\"./dcgan_gan.h5\")\n","gan.save_weights(\"./dcgan_gan_weights.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bSQdjsBjvs0o"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":0}
