{"cells":[{"cell_type":"markdown","metadata":{"id":"XSW84neQ4PdR"},"source":["# Bag of Words\n","\n","En este notebook vamos a ver un ejemplo práctico de la técnica de \"Bag of Words\".\n","\n","Como hemos visto, cuando operamos con textos, no hay ninguna operación matemática definida que pueda trabajar con ellos directamente. Por ejemplo, no podemos combinar las palabras _\"hola\"_ y _\"adiós\"_. \n","\n","Por lo tanto, para poder utilizar textos definidos en lenguaje natural, independientemente del idioma utilizado, necesitamos **transformar estos textos en vectores numéricos** que los representen.\n","\n","La técnica más conocida para hacer esta transformación se llama ***bolsa de palabras*** o **Bag of Words**. \n","\n","Veamos cómo funciona con un ejemplo. Supongamos que tenemos el siguiente texto\n","\n","> *El miedo es el camino hacia el Lado Oscuro. El miedo lleva a la ira, la ira lleva al odio, el odio lleva al sufrimiento. Percibo mucho miedo en ti.* — Yoda a Anakin en el Consejo Jedi.\n","\n","El primer paso que debemos realizar es la limpieza del dataset de caracteres extraños y homogeneizarlo a minúsculas:\n","\n","> el miedo es el camino hacia el lado oscuro el miedo lleva a la ira la ira lleva al odio el odio lleva al sufrimiento percibo mucho miedo en ti\n","\n","Después, procederemos con la **tokenización**, que consiste en transformar el texto anterior en una matriz de palabras. \n","\n","Es decir, vamos a separar cada una de las palabras que componen la frase anterior utilizando espacios separadores. Por tanto, obtendríamos la siguiente lista de *tokens*:\n","\n","`['el', 'miedo', 'es', 'el', 'camino, 'hacia', 'el', 'lado', 'oscuro', 'el', 'miedo', 'lleva', 'a', 'la', 'ira', 'la', 'ira', 'lleva', 'al', 'odio', 'el', 'odio', 'lleva', 'al', 'sufrimiento', 'percibo', 'mucho', 'miedo', 'en', 'ti']`.\n","\n","A partir de la lista anterior podemos construir un **diccionario** que contenga todas las palabras definidas en nuestro vocabulario. \n","\n","Entendemos por \"nuestro vocabulario\" las palabras que aparecen en los textos que estamos analizando. Así, analizando los *tokens* anteriores construiremos el siguiente diccionario:\n","\n","`['el', 'miedo', 'es', 'camino, 'hacia', 'lado', 'oscuro', 'lleva', 'a', 'la', 'ira', 'al', 'odio', 'sufrimiento', 'percibo', 'mucho', 'en', 'ti']`\n","\n","Por último, tenemos que transformar el texto original en un vector numérico de forma que las posiciones del vector representen las posiciones de las palabras del diccionario y los valores del vector representen el número de apariciones de la palabra del diccionario en el texto analizado. \n","\n","Dado que nuestro diccionario consta de 18 palabras, nuestro texto quedaría definido por el siguiente vector\n","\n","`[5, 3, 1, 1, 1, 1, 1, 3, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1]`\n","\n","Viéndolo en formato tabla es más fácil de detectar:\n","\n","| | el | miedo | es | camino | hacia | lado | oscuro | lleva | a | la | ira | al | odio | sufrimiento | percibo | mucho | en | ti |\n","| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n","| Frecuencia | 5 | 3 | 1 | 1 | 1 | 1 | 1 | 3 | 1 | 2 | 2 | 2 | 2 | 1 | 1 | 1 | 1 | 1 |\n","\n","Analizándolo vemos que la palabra *'miedo'* se repite 3 veces, la palabra *'ira'* 2, la palabra *'el'* 5, y así sucesivamente."]},{"cell_type":"markdown","metadata":{"id":"0d0cwDCs8LlP"},"source":["En este caso hemos dejado la limpieza de las stop-words para después, pues nos interesaba ver el cambio entre el antes y el después.\n","\n","Si eliminaramos las stop-words veríamos que desparecen los artículos, determinantes, preposiciones, etc.\n","\n","En lugar de hacerlo manualmente, como hasta ahora, vamos a hacerlo con Python."]},{"cell_type":"markdown","metadata":{"id":"qj4TXhJy5Oo5"},"source":["La forma más rápida de hacerlo es utilizando el objeto `CountVectorizer` del paquete `feature_extraction.text` de la librería `scikit-learn`.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2020-03-02T13:43:39.029322Z","start_time":"2020-03-02T13:43:38.865734Z"},"id":"QzzEeRLsFxyS"},"outputs":[],"source":["import sklearn\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2020-03-02T13:43:39.038618Z","start_time":"2020-03-02T13:43:39.030666Z"},"id":"O4_vzJSlU68R"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","count_vectorizer = CountVectorizer()"]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2020-03-02T13:43:39.043934Z","start_time":"2020-03-02T13:43:39.040135Z"},"id":"rrkeG7G2VHRx"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[2 1 5 1 1 1 2 2 1 3 3 1 2 1 1 1 1]]\n"]}],"source":["corpus = [\n","    \"El miedo es el camino hacia el Lado Oscuro. El miedo lleva a la ira, la ira lleva al odio, el odio lleva al sufrimiento. Percibo mucho miedo en ti.\"\n","]\n","\n","X = count_vectorizer.fit_transform(corpus) # Fit the Data: vector with the amount of times a word appears in the corpus\n","\n","print(X.toarray())\n"]},{"cell_type":"markdown","metadata":{"id":"g2JPvuPCVEs9"},"source":["Podemos ver el mapeo mediante la función `get_feature_names_out()`. Como podéis observar, ésta función detecta los símbolos de puntuación y los ignora."]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2020-03-02T13:43:39.052240Z","start_time":"2020-03-02T13:43:39.049943Z"},"id":"uUXOKN5eWP9H"},"outputs":[{"name":"stdout","output_type":"stream","text":["['al' 'camino' 'el' 'en' 'es' 'hacia' 'ira' 'la' 'lado' 'lleva' 'miedo'\n"," 'mucho' 'odio' 'oscuro' 'percibo' 'sufrimiento' 'ti']\n"]}],"source":["print(count_vectorizer.get_feature_names_out()) # Get feature names whihle ignoring accents"]},{"cell_type":"markdown","metadata":{"id":"wLCdq7vX9DPG"},"source":["Veamos ahora si elimináramos las stop-words:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"YLlSPoPWIZkL"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.8.1)\n","Requirement already satisfied: click in c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (8.1.3)\n","Requirement already satisfied: joblib in c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (2023.5.5)\n","Requirement already satisfied: tqdm in c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk) (4.65.0)\n","Requirement already satisfied: colorama in c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click->nltk) (0.4.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["#!sudo pip install -U nltk\n","# %pip install nltk"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"IypXswWNU9HT"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\franz\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')"]},{"cell_type":"markdown","metadata":{"id":"dXJ4tIRR9jSQ"},"source":["En este caso, es necesario limpiar el dataset y homogeneizar a minusculas antes de usar `nltk`:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"r4mYsq2LTZ7c"},"outputs":[{"name":"stdout","output_type":"stream","text":["!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"]}],"source":["import re\n","import string\n","print(string.punctuation)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"8zz8eWS4UCf4"},"outputs":[{"name":"stdout","output_type":"stream","text":["!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~“”¡¿\n"]}],"source":["# añadimos algunos más que no están en string.punctuation, como las comillas y \n","# las aperturas de interrogación/exclamación\n","# si no los añadiésemos, no se eliminarían\n","chars = string.punctuation + '“”¡¿'\n","print(chars)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"dntEu4LYTiDL"},"outputs":[{"name":"stdout","output_type":"stream","text":["El miedo es el camino hacia el Lado Oscuro El miedo lleva a la ira la ira lleva al odio el odio lleva al sufrimiento Percibo mucho miedo en ti\n"]}],"source":["re_punc = re.compile('[%s]' % re.escape(chars))\n","# eliminar la puntuación de cada palabra\n","texto = re_punc.sub('', corpus[0])\n","print(texto)"]},{"cell_type":"markdown","metadata":{"id":"EpHXy9LaHt18"},"source":["Convertimos el texto a minúsculas:"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"c8nsuU31ISMD"},"outputs":[{"name":"stdout","output_type":"stream","text":["el miedo es el camino hacia el lado oscuro el miedo lleva a la ira la ira lleva al odio el odio lleva al sufrimiento percibo mucho miedo en ti\n"]}],"source":["texto = texto.lower()\n","print(texto)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"xDc8TzzewziV"},"outputs":[{"name":"stdout","output_type":"stream","text":["['el', 'miedo', 'es', 'el', 'camino', 'hacia', 'el', 'lado', 'oscuro', 'el', 'miedo', 'lleva', 'a', 'la', 'ira', 'la', 'ira', 'lleva', 'al', 'odio', 'el', 'odio', 'lleva', 'al', 'sufrimiento', 'percibo', 'mucho', 'miedo', 'en', 'ti']\n"]}],"source":["stop_words = stopwords.words('spanish')\n","palabras = texto.split(' ')\n","print(palabras)"]},{"cell_type":"markdown","metadata":{"id":"9SZiAtvf-DE6"},"source":["Eliminamos las stop-words:"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"lSyfyWO79dc5"},"outputs":[{"name":"stdout","output_type":"stream","text":["['miedo', 'camino', 'hacia', 'lado', 'oscuro', 'miedo', 'lleva', 'ira', 'ira', 'lleva', 'odio', 'odio', 'lleva', 'sufrimiento', 'percibo', 'miedo']\n"]}],"source":["palabras_limpias = [p for p in palabras if p not in stop_words]\n","print(palabras_limpias)"]},{"cell_type":"markdown","metadata":{"id":"GvWLiMSv-njd"},"source":["Unimos el texto de nuevo:"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"hSXYC4OS-ouF"},"outputs":[{"name":"stdout","output_type":"stream","text":["miedo camino hacia lado oscuro miedo lleva ira ira lleva odio odio lleva sufrimiento percibo miedo\n"]}],"source":["texto_limpio = ' '.join(palabras_limpias)\n","print(texto_limpio)"]},{"cell_type":"markdown","metadata":{"id":"J8iAu8pg-FUX"},"source":["Y aplicamos la técnica de Bag of Words:"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"O1L7-zyg-IhC"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1 1 2 1 3 3 2 1 1 1]]\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","count_vectorizer = CountVectorizer()\n","\n","# el objeto count_vectorizer necesita una lista de textos para funcionar\n","X = count_vectorizer.fit_transform([texto_limpio])\n","print(X.toarray())"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Aq6UTNu7-dBT"},"outputs":[{"name":"stdout","output_type":"stream","text":["['camino' 'hacia' 'ira' 'lado' 'lleva' 'miedo' 'odio' 'oscuro' 'percibo'\n"," 'sufrimiento']\n"]}],"source":["print(count_vectorizer.get_feature_names_out())"]},{"cell_type":"markdown","metadata":{"id":"bHYW85bn-yvX"},"source":["Comparadlo con la versión sin limpiar:"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"y4h-fv92-4K8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[2 1 5 1 1 1 2 2 1 3 3 1 2 1 1 1 1]]\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","count_vectorizer = CountVectorizer()\n","\n","# el objeto count_vectorizer necesita una lista de textos para funcionar\n","X = count_vectorizer.fit_transform(corpus)\n","print(X.toarray())"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"s7KUBXAP-4K_"},"outputs":[{"name":"stdout","output_type":"stream","text":["['al' 'camino' 'el' 'en' 'es' 'hacia' 'ira' 'la' 'lado' 'lleva' 'miedo'\n"," 'mucho' 'odio' 'oscuro' 'percibo' 'sufrimiento' 'ti']\n"]}],"source":["print(count_vectorizer.get_feature_names_out())"]},{"cell_type":"markdown","metadata":{"id":"kxiWIveA88_K"},"source":["### Ejercicio 1\n","\n","Realiza la limpieza del dataset, la eliminación de stop-words y la vectorización del texto (bag of words) del siguiente texto:\n","\n","> \"¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.\" - Maestre Aemon, Juego de Tronos"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"4lQuM5Xn_X0L"},"outputs":[],"source":["corpus = ['¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.']"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"6bqjdjkj_fbD"},"outputs":[{"name":"stdout","output_type":"stream","text":["Qué es el honor comparado con el amor de una mujer Qué es el deber comparado con el calor de un hijo recién nacido entre los brazos o el recuerdo de la sonrisa de un hermano Aire y palabras Aire y palabras Solo somos humanos y los dioses nos hicieron para el amor Es nuestra mayor gloria y nuestra peor tragedia\n","qué es el honor comparado con el amor de una mujer qué es el deber comparado con el calor de un hijo recién nacido entre los brazos o el recuerdo de la sonrisa de un hermano aire y palabras aire y palabras solo somos humanos y los dioses nos hicieron para el amor es nuestra mayor gloria y nuestra peor tragedia\n","que es el honor comparado con el amor de una mujer que es el deber comparado con el calor de un hijo recien nacido entre los brazos o el recuerdo de la sonrisa de un hermano aire y palabras aire y palabras solo somos humanos y los dioses nos hicieron para el amor es nuestra mayor gloria y nuestra peor tragedia\n","['honor', 'comparado', 'amor', 'mujer', 'deber', 'comparado', 'calor', 'hijo', 'recien', 'nacido', 'brazos', 'recuerdo', 'sonrisa', 'hermano', 'aire', 'palabras', 'aire', 'palabras', 'solo', 'humanos', 'dioses', 'hicieron', 'amor', 'mayor', 'gloria', 'peor', 'tragedia']\n"]}],"source":["# 1. Limpieza ddel texto: puntación, minúscula y accentos, stopwords\n","import unicodedata\n","\n","chars = string.punctuation + '“”¡¿'\n","re_pun = re.compile('[%s]' % re.escape(chars)) \n","texto_sin_puntuacion = re_pun.sub('', corpus[0]) \n","print(texto_sin_puntuacion)\n","\n","texto_minuscula = texto_sin_puntuacion.lower() \n","print(texto_minuscula)\n","\n","texto_sin_acentos = unicodedata.normalize('NFD', texto_minuscula).encode('ascii', 'ignore').decode(\"utf-8\")\n","print(texto_sin_acentos)\n","\n","palabras = texto_sin_acentos.split(' ')\n","palabras_limpias = [p for p in palabras if p not in stop_words]\n","print(palabras_limpias)\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['honor', 'comparado', 'amor', 'mujer', 'deber', 'comparado', 'calor', 'hijo', 'recien', 'nacido', 'brazos', 'recuerdo', 'sonrisa', 'hermano', 'aire', 'palabras', 'aire', 'palabras', 'solo', 'humanos', 'dioses', 'hicieron', 'amor', 'mayor', 'gloria', 'peor', 'tragedia']\n"]}],"source":["# 2. Tokenización\n","## ya separado en palabras para la limpieza de stopwords\n","print(palabras_limpias)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1]]\n","['aire' 'amor' 'brazos' 'calor' 'comparado' 'deber' 'dioses' 'gloria'\n"," 'hermano' 'hicieron' 'hijo' 'honor' 'humanos' 'mayor' 'mujer' 'nacido'\n"," 'palabras' 'peor' 'recien' 'recuerdo' 'solo' 'sonrisa' 'tragedia']\n"]}],"source":["# 3. construir el vocabulario (todas las palabras únicas del texto) y crear el matrix (en este caso con sola 1 fila)\n","texto_limpio = ' '.join(palabras_limpias)\n","X = count_vectorizer.fit_transform([texto_limpio])\n","print(X.toarray())\n","print(count_vectorizer.get_feature_names_out())"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aire</th>\n","      <th>amor</th>\n","      <th>brazos</th>\n","      <th>calor</th>\n","      <th>comparado</th>\n","      <th>deber</th>\n","      <th>dioses</th>\n","      <th>gloria</th>\n","      <th>hermano</th>\n","      <th>hicieron</th>\n","      <th>...</th>\n","      <th>mayor</th>\n","      <th>mujer</th>\n","      <th>nacido</th>\n","      <th>palabras</th>\n","      <th>peor</th>\n","      <th>recien</th>\n","      <th>recuerdo</th>\n","      <th>solo</th>\n","      <th>sonrisa</th>\n","      <th>tragedia</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 23 columns</p>\n","</div>"],"text/plain":["   aire  amor  brazos  calor  comparado  deber  dioses  gloria  hermano  \\\n","0   1.0   2.0     2.0    1.0        1.0    1.0     1.0     1.0      1.0   \n","\n","   hicieron  ...  mayor  mujer  nacido  palabras  peor  recien  recuerdo  \\\n","0       1.0  ...    2.0    2.0     1.0       1.0   1.0     1.0       1.0   \n","\n","   solo  sonrisa  tragedia  \n","0   1.0      1.0       1.0  \n","\n","[1 rows x 23 columns]"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["# 4. codificar el texto en función del vocabulario\n","import pandas as pd\n","df = pd.DataFrame(X, columns=count_vectorizer.get_feature_names_out())\n","df"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'honor': 1, 'comparado': 2, 'amor': 2, 'mujer': 1, 'deber': 1, 'calor': 1, 'hijo': 1, 'recien': 1, 'nacido': 1, 'brazos': 1, 'recuerdo': 1, 'sonrisa': 1, 'hermano': 1, 'aire': 2, 'palabras': 2, 'solo': 1, 'humanos': 1, 'dioses': 1, 'hicieron': 1, 'mayor': 1, 'gloria': 1, 'peor': 1, 'tragedia': 1}\n"]}],"source":["# alternative en bucle: 3. construir el vocabulario\n","vocab = {}\n","for p in palabras_limpias:\n","    if not p in vocab:\n","        vocab[p] = 1\n","    else:\n","        vocab[p] += 1\n","print(vocab)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aire</th>\n","      <th>amor</th>\n","      <th>brazos</th>\n","      <th>calor</th>\n","      <th>comparado</th>\n","      <th>deber</th>\n","      <th>dioses</th>\n","      <th>gloria</th>\n","      <th>hermano</th>\n","      <th>hicieron</th>\n","      <th>...</th>\n","      <th>mayor</th>\n","      <th>mujer</th>\n","      <th>nacido</th>\n","      <th>palabras</th>\n","      <th>peor</th>\n","      <th>recien</th>\n","      <th>recuerdo</th>\n","      <th>solo</th>\n","      <th>sonrisa</th>\n","      <th>tragedia</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 23 columns</p>\n","</div>"],"text/plain":["   aire  amor  brazos  calor  comparado  deber  dioses  gloria  hermano  \\\n","0     2     2       1      1          2      1       1       1        1   \n","\n","   hicieron  ...  mayor  mujer  nacido  palabras  peor  recien  recuerdo  \\\n","0         1  ...      1      1       1         2     1       1         1   \n","\n","   solo  sonrisa  tragedia  \n","0     1        1         1  \n","\n","[1 rows x 23 columns]"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["# 4. codificar el texto en función del vocabulario - matrix de frecuencias\n","df = pd.DataFrame([vocab]).reindex(sorted(df.columns), axis=1)\n","df"]},{"cell_type":"markdown","metadata":{"id":"_rWIR9XACDvM"},"source":["### Ejercicio 2\n","\n","Realiza la limpieza del dataset, la eliminación de stop-words y la vectorización del texto (bag of words) del siguiente *corpus* de documentos:\n","\n","> \"Cuando se juega al Juego de Tronos, solo se puede ganar o morir.\" - Cersei Lannister\n","\n","> \"Por qué será que en cuanto un hombre construye un muro, su vecino inmediatamente quiere saber qué hay del otro lado.\" - Tyrion Lannister\n","\n","> \"¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.\" - Maestre Aemon, Juego de Tronos\n","\n","> \"El hombre que dicta la condena debe blandir la espada.\" - Eddard Stark\n","\n","> \"El poder reside donde los hombres creen que reside. Es un truco, una sombra en la pared. Y un hombre muy pequeño puede proyectar una sombra muy grande.\" - Lord Varys"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"uqug2lmKCDvO"},"outputs":[],"source":["corpus = [\n","    \"Cuando se juega al Juego de Tronos, solo se puede ganar o morir.\",\n","    \"Por qué será que en cuanto un hombre construye un muro, su vecino inmediatamente quiere saber qué hay del otro lado.\",\n","    \"¿Qué es el honor, comparado con el amor de una mujer? ¿Qué es el deber, comparado con el calor de un hijo recién nacido entre los brazos, o el recuerdo de la sonrisa de un hermano? Aire y palabras. Aire y palabras. Solo somos humanos, y los dioses nos hicieron para el amor. Es nuestra mayor gloria y nuestra peor tragedia.\",\n","    \"El hombre que dicta la condena debe blandir la espada.\",\n","    \"El poder reside donde los hombres creen que reside. Es un truco, una sombra en la pared. Y un hombre muy pequeño puede proyectar una sombra muy grande.\"\n","]"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['poder', 'reside', 'hombres', 'creen', 'reside', 'truco', 'sombra', 'pared', 'hombre', 'pequeno', 'puede', 'proyectar', 'sombra', 'grande']\n","['juega juego tronos solo puede ganar morir', 'sera cuanto hombre construye muro vecino inmediatamente quiere saber lado', 'honor comparado amor mujer deber comparado calor hijo recien nacido brazos recuerdo sonrisa hermano aire palabras aire palabras solo humanos dioses hicieron amor mayor gloria peor tragedia', 'hombre dicta condena debe blandir espada', 'poder reside hombres creen reside truco sombra pared hombre pequeno puede proyectar sombra grande']\n"]}],"source":["# Limpieza ddel texto: puntación, minúscula y accentos, stopwords\n","\n","chars = string.punctuation + '“”¡¿'\n","re_pun = re.compile('[%s]' % re.escape(chars)) \n","\n","for i in range(len(corpus)):\n","    corpus[i] = re_pun.sub('', corpus[i])\n","    corpus[i] = corpus[i].lower()\n","    corpus[i] = unicodedata.normalize('NFD', corpus[i]).encode('ascii', 'ignore').decode(\"utf-8\")\n","    palabras = corpus[i].split(' ')\n","    palabras_limpias = [p for p in palabras if p not in stop_words]\n","    corpus[i] = ' '.join(palabras_limpias)\n","print(palabras_limpias)\n","print(corpus)\n"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0\n","  0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0]\n"," [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0\n","  0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1]\n"," [2 2 0 1 1 2 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 1 2 0\n","  1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0]\n"," [0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n","  0 1 1 1 1 0 0 0 2 0 0 0 2 0 0 0 1 0]]\n","['aire' 'amor' 'blandir' 'brazos' 'calor' 'comparado' 'condena'\n"," 'construye' 'creen' 'cuanto' 'debe' 'deber' 'dicta' 'dioses' 'espada'\n"," 'ganar' 'gloria' 'grande' 'hermano' 'hicieron' 'hijo' 'hombre' 'hombres'\n"," 'honor' 'humanos' 'inmediatamente' 'juega' 'juego' 'lado' 'mayor' 'morir'\n"," 'mujer' 'muro' 'nacido' 'palabras' 'pared' 'peor' 'pequeno' 'poder'\n"," 'proyectar' 'puede' 'quiere' 'recien' 'recuerdo' 'reside' 'saber' 'sera'\n"," 'solo' 'sombra' 'sonrisa' 'tragedia' 'tronos' 'truco' 'vecino']\n"]}],"source":["# Create the matrix of word frequencies\n","count_vectorizer = CountVectorizer()\n","matrix = count_vectorizer.fit_transform(corpus)\n","\n","# Get the list of words (column names)\n","words = count_vectorizer.get_feature_names_out()\n","\n","# Print the matrix and the list of words\n","print(matrix.toarray())\n","print(words)"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"'method' object is not iterable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\franz\\Documents\\GitHub\\EDEM2022\\3AnalisisYAprendizajeAutomatico\\nlp\\1 - NLP\\3 - Bag of Words.ipynb Cell 41\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franz/Documents/GitHub/EDEM2022/3AnalisisYAprendizajeAutomatico/nlp/1%20-%20NLP/3%20-%20Bag%20of%20Words.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create a DataFrame from the matrix\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/franz/Documents/GitHub/EDEM2022/3AnalisisYAprendizajeAutomatico/nlp/1%20-%20NLP/3%20-%20Bag%20of%20Words.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(matrix\u001b[39m.\u001b[39;49mtoarray(), columns\u001b[39m=\u001b[39;49mcount_vectorizer\u001b[39m.\u001b[39;49mget_feature_names_out)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franz/Documents/GitHub/EDEM2022/3AnalisisYAprendizajeAutomatico/nlp/1%20-%20NLP/3%20-%20Bag%20of%20Words.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(df)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:722\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    712\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    713\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    714\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    720\u001b[0m         )\n\u001b[0;32m    721\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 722\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    723\u001b[0m             data,\n\u001b[0;32m    724\u001b[0m             index,\n\u001b[0;32m    725\u001b[0m             columns,\n\u001b[0;32m    726\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    727\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    728\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    729\u001b[0m         )\n\u001b[0;32m    731\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:345\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    335\u001b[0m     values \u001b[39m=\u001b[39m sanitize_array(\n\u001b[0;32m    336\u001b[0m         values,\n\u001b[0;32m    337\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    341\u001b[0m         allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    342\u001b[0m     )\n\u001b[0;32m    344\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m--> 345\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[0;32m    346\u001b[0m     values\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], values\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], index\u001b[39m=\u001b[39;49mindex, columns\u001b[39m=\u001b[39;49mcolumns\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    349\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:753\u001b[0m, in \u001b[0;36m_get_axes\u001b[1;34m(N, K, index, columns)\u001b[0m\n\u001b[0;32m    751\u001b[0m     columns \u001b[39m=\u001b[39m default_index(K)\n\u001b[0;32m    752\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 753\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    754\u001b[0m \u001b[39mreturn\u001b[39;00m index, columns\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:7333\u001b[0m, in \u001b[0;36mensure_index\u001b[1;34m(index_like, copy)\u001b[0m\n\u001b[0;32m   7331\u001b[0m         \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39m_with_infer(index_like, copy\u001b[39m=\u001b[39mcopy, tupleize_cols\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   7332\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 7333\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39;49m_with_infer(index_like, copy\u001b[39m=\u001b[39;49mcopy)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:716\u001b[0m, in \u001b[0;36mIndex._with_infer\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[0;32m    715\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.*the Index constructor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 716\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    718\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m _dtype_obj \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_is_multi:\n\u001b[0;32m    719\u001b[0m     \u001b[39m# error: Argument 1 to \"maybe_convert_objects\" has incompatible type\u001b[39;00m\n\u001b[0;32m    720\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     \u001b[39m# \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     values \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result\u001b[39m.\u001b[39m_values)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:565\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[39mreturn\u001b[39;00m MultiIndex\u001b[39m.\u001b[39mfrom_tuples(\n\u001b[0;32m    561\u001b[0m             data, names\u001b[39m=\u001b[39mname \u001b[39mor\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    562\u001b[0m         )\n\u001b[0;32m    563\u001b[0m \u001b[39m# other iterable of some kind\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m subarr \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39;49masarray_tuplesafe(data, dtype\u001b[39m=\u001b[39;49m_dtype_obj)\n\u001b[0;32m    566\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    567\u001b[0m     \u001b[39m# with e.g. a list [1, 2, 3] casting to numeric is _not_ deprecated\u001b[39;00m\n\u001b[0;32m    568\u001b[0m     subarr \u001b[39m=\u001b[39m _maybe_cast_data_without_dtype(\n\u001b[0;32m    569\u001b[0m         subarr, cast_numeric_deprecated\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    570\u001b[0m     )\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\common.py:238\u001b[0m, in \u001b[0;36masarray_tuplesafe\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39masarray_tuplesafe\u001b[39m(values: Iterable, dtype: NpDtype \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ArrayLike:\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(values, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(values, \u001b[39m\"\u001b[39m\u001b[39m__array__\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m--> 238\u001b[0m         values \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(values)\n\u001b[0;32m    239\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(values, ABCIndex):\n\u001b[0;32m    240\u001b[0m         \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39m_values\n","\u001b[1;31mTypeError\u001b[0m: 'method' object is not iterable"]}],"source":["# Create a DataFrame from the matrix\n","df = pd.DataFrame(matrix.toarray(), columns=words)\n","print(df)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM5aVQ4On9elKnNxJQug6VZ","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
