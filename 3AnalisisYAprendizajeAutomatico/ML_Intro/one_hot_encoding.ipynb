{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>booking_date</th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>price</th>\n",
       "      <th>sales channel</th>\n",
       "      <th>ant</th>\n",
       "      <th>airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user5</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>MAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>online</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user7</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>DUB</td>\n",
       "      <td>147.500000</td>\n",
       "      <td>online</td>\n",
       "      <td>38.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user4</td>\n",
       "      <td>02/11/2018</td>\n",
       "      <td>TFS</td>\n",
       "      <td>24.049999</td>\n",
       "      <td>online</td>\n",
       "      <td>19.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user8</td>\n",
       "      <td>29/10/2018</td>\n",
       "      <td>MAD</td>\n",
       "      <td>59.709999</td>\n",
       "      <td>online</td>\n",
       "      <td>8.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user7</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.299999</td>\n",
       "      <td>call center</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>user2</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>JMK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>online</td>\n",
       "      <td>29.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>user10</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>SVQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>online</td>\n",
       "      <td>39.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>user4</td>\n",
       "      <td>30/10/2018</td>\n",
       "      <td>MAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>online</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>user10</td>\n",
       "      <td>02/11/2018</td>\n",
       "      <td>CDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>online</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>user6</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>MAD</td>\n",
       "      <td>98.339996</td>\n",
       "      <td>online</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user booking_date origin_airport       price sales channel   ant  \\\n",
       "0     user5   01/11/2018            MAD         NaN        online   NaN   \n",
       "1     user7   01/11/2018            DUB  147.500000        online  38.0   \n",
       "2     user4   02/11/2018            TFS   24.049999        online  19.0   \n",
       "3     user8   29/10/2018            MAD   59.709999        online   8.0   \n",
       "4     user7   01/11/2018            NaN   37.299999   call center   4.0   \n",
       "..      ...          ...            ...         ...           ...   ...   \n",
       "995   user2   01/11/2018            JMK         NaN        online  29.0   \n",
       "996  user10   01/11/2018            SVQ         NaN        online  39.0   \n",
       "997   user4   30/10/2018            MAD         NaN        online   5.0   \n",
       "998  user10   02/11/2018            CDG         NaN        online   4.0   \n",
       "999   user6   01/11/2018            MAD   98.339996        online   0.0   \n",
       "\n",
       "    airline  \n",
       "0        i2  \n",
       "1        i2  \n",
       "2        i2  \n",
       "3        i2  \n",
       "4        i2  \n",
       "..      ...  \n",
       "995      i2  \n",
       "996      i2  \n",
       "997      i2  \n",
       "998      i2  \n",
       "999      i2  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer datos\n",
    "dat = pd.read_csv(\"datasets/i2.csv\", sep = \";\")\n",
    "\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>booking_date</th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>price</th>\n",
       "      <th>sales channel</th>\n",
       "      <th>ant</th>\n",
       "      <th>airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user5</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>MAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user7</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>DUB</td>\n",
       "      <td>147.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user4</td>\n",
       "      <td>02/11/2018</td>\n",
       "      <td>TFS</td>\n",
       "      <td>24.049999</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user8</td>\n",
       "      <td>29/10/2018</td>\n",
       "      <td>MAD</td>\n",
       "      <td>59.709999</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user7</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.299999</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>user2</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>JMK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>user10</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>SVQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>user4</td>\n",
       "      <td>30/10/2018</td>\n",
       "      <td>MAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>user10</td>\n",
       "      <td>02/11/2018</td>\n",
       "      <td>CDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>user6</td>\n",
       "      <td>01/11/2018</td>\n",
       "      <td>MAD</td>\n",
       "      <td>98.339996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user booking_date origin_airport       price sales channel   ant  \\\n",
       "0     user5   01/11/2018            MAD         NaN             1   NaN   \n",
       "1     user7   01/11/2018            DUB  147.500000             1  38.0   \n",
       "2     user4   02/11/2018            TFS   24.049999             1  19.0   \n",
       "3     user8   29/10/2018            MAD   59.709999             1   8.0   \n",
       "4     user7   01/11/2018            NaN   37.299999             2   4.0   \n",
       "..      ...          ...            ...         ...           ...   ...   \n",
       "995   user2   01/11/2018            JMK         NaN             1  29.0   \n",
       "996  user10   01/11/2018            SVQ         NaN             1  39.0   \n",
       "997   user4   30/10/2018            MAD         NaN             1   5.0   \n",
       "998  user10   02/11/2018            CDG         NaN             1   4.0   \n",
       "999   user6   01/11/2018            MAD   98.339996             1   0.0   \n",
       "\n",
       "    airline  \n",
       "0        i2  \n",
       "1        i2  \n",
       "2        i2  \n",
       "3        i2  \n",
       "4        i2  \n",
       "..      ...  \n",
       "995      i2  \n",
       "996      i2  \n",
       "997      i2  \n",
       "998      i2  \n",
       "999      i2  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opcion 1: Reemplazar valores de la columna sales channel con valores numÃ©ricos\n",
    "## loc: localiza filas y columnas por etiqueta o condiciÃ³n\n",
    "dat.loc[dat['sales channel'] == 'online', 'sales channel'] = 1\n",
    "dat.loc[dat['sales channel'] == 'call center', 'sales channel'] = 2\n",
    "dat.loc[dat['sales channel'] == 'travel agency', 'sales channel'] = 3\n",
    "\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>booking_date</th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>price</th>\n",
       "      <th>sales channel</th>\n",
       "      <th>ant</th>\n",
       "      <th>airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>147.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24.049999</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>59.709999</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.299999</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>user2</td>\n",
       "      <td>1</td>\n",
       "      <td>JMK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>user10</td>\n",
       "      <td>1</td>\n",
       "      <td>SVQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3</td>\n",
       "      <td>30/10/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>user10</td>\n",
       "      <td>2</td>\n",
       "      <td>CDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>user6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98.339996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user booking_date origin_airport       price sales channel   ant  \\\n",
       "0         1            1              1         NaN             1   NaN   \n",
       "1         2            1              2  147.500000             1  38.0   \n",
       "2         3            2              3   24.049999             1  19.0   \n",
       "3     user8            3              1   59.709999             1   8.0   \n",
       "4         2            1            NaN   37.299999             2   4.0   \n",
       "..      ...          ...            ...         ...           ...   ...   \n",
       "995   user2            1            JMK         NaN             1  29.0   \n",
       "996  user10            1            SVQ         NaN             1  39.0   \n",
       "997       3   30/10/2018              1         NaN             1   5.0   \n",
       "998  user10            2            CDG         NaN             1   4.0   \n",
       "999   user6            1              1   98.339996             1   0.0   \n",
       "\n",
       "    airline  \n",
       "0        i2  \n",
       "1        i2  \n",
       "2        i2  \n",
       "3        i2  \n",
       "4        i2  \n",
       "..      ...  \n",
       "995      i2  \n",
       "996      i2  \n",
       "997      i2  \n",
       "998      i2  \n",
       "999      i2  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opciÃ³n 2: Reemplazar valores de la columna sales channel con valores numÃ©ricos\n",
    "## unique: devuelve los valores Ãºnicos de una columna\n",
    "dat.loc[dat['sales channel'] == dat['sales channel'].unique()[0], 'sales channel'] = 1\n",
    "dat.loc[dat['sales channel'] == dat['sales channel'].unique()[1], 'sales channel'] = 2\n",
    "dat.loc[dat['sales channel'] == dat['sales channel'].unique()[2], 'sales channel'] = 3\n",
    "\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>booking_date</th>\n",
       "      <th>origin_airport</th>\n",
       "      <th>price</th>\n",
       "      <th>sales channel</th>\n",
       "      <th>ant</th>\n",
       "      <th>airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>147.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24.049999</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>59.709999</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.299999</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>user2</td>\n",
       "      <td>1</td>\n",
       "      <td>JMK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>user10</td>\n",
       "      <td>1</td>\n",
       "      <td>SVQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3</td>\n",
       "      <td>30/10/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>user10</td>\n",
       "      <td>2</td>\n",
       "      <td>CDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>user6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98.339996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user booking_date origin_airport       price sales channel   ant  \\\n",
       "0         1            1              1         NaN             1   NaN   \n",
       "1         2            1              2  147.500000             1  38.0   \n",
       "2         3            2              3   24.049999             1  19.0   \n",
       "3     user8            3              1   59.709999             1   8.0   \n",
       "4         2            1            NaN   37.299999             2   4.0   \n",
       "..      ...          ...            ...         ...           ...   ...   \n",
       "995   user2            1            JMK         NaN             1  29.0   \n",
       "996  user10            1            SVQ         NaN             1  39.0   \n",
       "997       3   30/10/2018              1         NaN             1   5.0   \n",
       "998  user10            2            CDG         NaN             1   4.0   \n",
       "999   user6            1              1   98.339996             1   0.0   \n",
       "\n",
       "    airline  \n",
       "0        i2  \n",
       "1        i2  \n",
       "2        i2  \n",
       "3        i2  \n",
       "4        i2  \n",
       "..      ...  \n",
       "995      i2  \n",
       "996      i2  \n",
       "997      i2  \n",
       "998      i2  \n",
       "999      i2  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opciÃ³n 3: Reemplazar valores de varias columnas con valores numÃ©ricos\n",
    "for c in ['user', 'booking_date', 'origin_airport']:\n",
    "    dat.loc[dat[c] == dat[c].unique()[0], c] = 1\n",
    "    dat.loc[dat[c] == dat[c].unique()[1], c] = 2\n",
    "    dat.loc[dat[c] == dat[c].unique()[2], c] = 3\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msparse_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;32mclass\u001b[0m \u001b[1;34m'numpy.float64'\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_frequency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_categories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Encode categorical features as a one-hot numeric array.\n",
      "\n",
      "The input to this transformer should be an array-like of integers or\n",
      "strings, denoting the values taken on by categorical (discrete) features.\n",
      "The features are encoded using a one-hot (aka 'one-of-K' or 'dummy')\n",
      "encoding scheme. This creates a binary column for each category and\n",
      "returns a sparse matrix or dense array (depending on the ``sparse_output``\n",
      "parameter)\n",
      "\n",
      "By default, the encoder derives the categories based on the unique values\n",
      "in each feature. Alternatively, you can also specify the `categories`\n",
      "manually.\n",
      "\n",
      "This encoding is needed for feeding categorical data to many scikit-learn\n",
      "estimators, notably linear models and SVMs with the standard kernels.\n",
      "\n",
      "Note: a one-hot encoding of y labels should use a LabelBinarizer\n",
      "instead.\n",
      "\n",
      "Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "categories : 'auto' or a list of array-like, default='auto'\n",
      "    Categories (unique values) per feature:\n",
      "\n",
      "    - 'auto' : Determine categories automatically from the training data.\n",
      "    - list : ``categories[i]`` holds the categories expected in the ith\n",
      "      column. The passed categories should not mix strings and numeric\n",
      "      values within a single feature, and should be sorted in case of\n",
      "      numeric values.\n",
      "\n",
      "    The used categories can be found in the ``categories_`` attribute.\n",
      "\n",
      "    .. versionadded:: 0.20\n",
      "\n",
      "drop : {'first', 'if_binary'} or an array-like of shape (n_features,),             default=None\n",
      "    Specifies a methodology to use to drop one of the categories per\n",
      "    feature. This is useful in situations where perfectly collinear\n",
      "    features cause problems, such as when feeding the resulting data\n",
      "    into an unregularized linear regression model.\n",
      "\n",
      "    However, dropping one category breaks the symmetry of the original\n",
      "    representation and can therefore induce a bias in downstream models,\n",
      "    for instance for penalized linear classification or regression models.\n",
      "\n",
      "    - None : retain all features (the default).\n",
      "    - 'first' : drop the first category in each feature. If only one\n",
      "      category is present, the feature will be dropped entirely.\n",
      "    - 'if_binary' : drop the first category in each feature with two\n",
      "      categories. Features with 1 or more than 2 categories are\n",
      "      left intact.\n",
      "    - array : ``drop[i]`` is the category in feature ``X[:, i]`` that\n",
      "      should be dropped.\n",
      "\n",
      "    When `max_categories` or `min_frequency` is configured to group\n",
      "    infrequent categories, the dropping behavior is handled after the\n",
      "    grouping.\n",
      "\n",
      "    .. versionadded:: 0.21\n",
      "       The parameter `drop` was added in 0.21.\n",
      "\n",
      "    .. versionchanged:: 0.23\n",
      "       The option `drop='if_binary'` was added in 0.23.\n",
      "\n",
      "    .. versionchanged:: 1.1\n",
      "        Support for dropping infrequent categories.\n",
      "\n",
      "sparse : bool, default=True\n",
      "    Will return sparse matrix if set True else will return an array.\n",
      "\n",
      "    .. deprecated:: 1.2\n",
      "       `sparse` is deprecated in 1.2 and will be removed in 1.4. Use\n",
      "       `sparse_output` instead.\n",
      "\n",
      "sparse_output : bool, default=True\n",
      "    Will return sparse matrix if set True else will return an array.\n",
      "\n",
      "    .. versionadded:: 1.2\n",
      "       `sparse` was renamed to `sparse_output`\n",
      "\n",
      "dtype : number type, default=float\n",
      "    Desired dtype of output.\n",
      "\n",
      "handle_unknown : {'error', 'ignore', 'infrequent_if_exist'},                      default='error'\n",
      "    Specifies the way unknown categories are handled during :meth:`transform`.\n",
      "\n",
      "    - 'error' : Raise an error if an unknown category is present during transform.\n",
      "    - 'ignore' : When an unknown category is encountered during\n",
      "      transform, the resulting one-hot encoded columns for this feature\n",
      "      will be all zeros. In the inverse transform, an unknown category\n",
      "      will be denoted as None.\n",
      "    - 'infrequent_if_exist' : When an unknown category is encountered\n",
      "      during transform, the resulting one-hot encoded columns for this\n",
      "      feature will map to the infrequent category if it exists. The\n",
      "      infrequent category will be mapped to the last position in the\n",
      "      encoding. During inverse transform, an unknown category will be\n",
      "      mapped to the category denoted `'infrequent'` if it exists. If the\n",
      "      `'infrequent'` category does not exist, then :meth:`transform` and\n",
      "      :meth:`inverse_transform` will handle an unknown category as with\n",
      "      `handle_unknown='ignore'`. Infrequent categories exist based on\n",
      "      `min_frequency` and `max_categories`. Read more in the\n",
      "      :ref:`User Guide <one_hot_encoder_infrequent_categories>`.\n",
      "\n",
      "    .. versionchanged:: 1.1\n",
      "        `'infrequent_if_exist'` was added to automatically handle unknown\n",
      "        categories and infrequent categories.\n",
      "\n",
      "min_frequency : int or float, default=None\n",
      "    Specifies the minimum frequency below which a category will be\n",
      "    considered infrequent.\n",
      "\n",
      "    - If `int`, categories with a smaller cardinality will be considered\n",
      "      infrequent.\n",
      "\n",
      "    - If `float`, categories with a smaller cardinality than\n",
      "      `min_frequency * n_samples`  will be considered infrequent.\n",
      "\n",
      "    .. versionadded:: 1.1\n",
      "        Read more in the :ref:`User Guide <one_hot_encoder_infrequent_categories>`.\n",
      "\n",
      "max_categories : int, default=None\n",
      "    Specifies an upper limit to the number of output features for each input\n",
      "    feature when considering infrequent categories. If there are infrequent\n",
      "    categories, `max_categories` includes the category representing the\n",
      "    infrequent categories along with the frequent categories. If `None`,\n",
      "    there is no limit to the number of output features.\n",
      "\n",
      "    .. versionadded:: 1.1\n",
      "        Read more in the :ref:`User Guide <one_hot_encoder_infrequent_categories>`.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "categories_ : list of arrays\n",
      "    The categories of each feature determined during fitting\n",
      "    (in order of the features in X and corresponding with the output\n",
      "    of ``transform``). This includes the category specified in ``drop``\n",
      "    (if any).\n",
      "\n",
      "drop_idx_ : array of shape (n_features,)\n",
      "    - ``drop_idx_[i]`` is the index in ``categories_[i]`` of the category\n",
      "      to be dropped for each feature.\n",
      "    - ``drop_idx_[i] = None`` if no category is to be dropped from the\n",
      "      feature with index ``i``, e.g. when `drop='if_binary'` and the\n",
      "      feature isn't binary.\n",
      "    - ``drop_idx_ = None`` if all the transformed features will be\n",
      "      retained.\n",
      "\n",
      "    If infrequent categories are enabled by setting `min_frequency` or\n",
      "    `max_categories` to a non-default value and `drop_idx[i]` corresponds\n",
      "    to a infrequent category, then the entire infrequent category is\n",
      "    dropped.\n",
      "\n",
      "    .. versionchanged:: 0.23\n",
      "       Added the possibility to contain `None` values.\n",
      "\n",
      "infrequent_categories_ : list of ndarray\n",
      "    Defined only if infrequent categories are enabled by setting\n",
      "    `min_frequency` or `max_categories` to a non-default value.\n",
      "    `infrequent_categories_[i]` are the infrequent categories for feature\n",
      "    `i`. If the feature `i` has no infrequent categories\n",
      "    `infrequent_categories_[i]` is None.\n",
      "\n",
      "    .. versionadded:: 1.1\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "OrdinalEncoder : Performs an ordinal (integer)\n",
      "  encoding of the categorical features.\n",
      "sklearn.feature_extraction.DictVectorizer : Performs a one-hot encoding of\n",
      "  dictionary items (also handles string-valued features).\n",
      "sklearn.feature_extraction.FeatureHasher : Performs an approximate one-hot\n",
      "  encoding of dictionary items or strings.\n",
      "LabelBinarizer : Binarizes labels in a one-vs-all\n",
      "  fashion.\n",
      "MultiLabelBinarizer : Transforms between iterable of\n",
      "  iterables and a multilabel format, e.g. a (samples x classes) binary\n",
      "  matrix indicating the presence of a class label.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Given a dataset with two features, we let the encoder find the unique\n",
      "values per feature and transform the data to a binary one-hot encoding.\n",
      "\n",
      ">>> from sklearn.preprocessing import OneHotEncoder\n",
      "\n",
      "One can discard categories not seen during `fit`:\n",
      "\n",
      ">>> enc = OneHotEncoder(handle_unknown='ignore')\n",
      ">>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
      ">>> enc.fit(X)\n",
      "OneHotEncoder(handle_unknown='ignore')\n",
      ">>> enc.categories_\n",
      "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
      ">>> enc.transform([['Female', 1], ['Male', 4]]).toarray()\n",
      "array([[1., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.]])\n",
      ">>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])\n",
      "array([['Male', 1],\n",
      "       [None, 2]], dtype=object)\n",
      ">>> enc.get_feature_names_out(['gender', 'group'])\n",
      "array(['gender_Female', 'gender_Male', 'group_1', 'group_2', 'group_3'], ...)\n",
      "\n",
      "One can always drop the first column for each feature:\n",
      "\n",
      ">>> drop_enc = OneHotEncoder(drop='first').fit(X)\n",
      ">>> drop_enc.categories_\n",
      "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
      ">>> drop_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n",
      "array([[0., 0., 0.],\n",
      "       [1., 1., 0.]])\n",
      "\n",
      "Or drop a column for feature only having 2 categories:\n",
      "\n",
      ">>> drop_binary_enc = OneHotEncoder(drop='if_binary').fit(X)\n",
      ">>> drop_binary_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n",
      "array([[0., 1., 0., 0.],\n",
      "       [1., 0., 1., 0.]])\n",
      "\n",
      "Infrequent categories are enabled by setting `max_categories` or `min_frequency`.\n",
      "\n",
      ">>> import numpy as np\n",
      ">>> X = np.array([[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3], dtype=object).T\n",
      ">>> ohe = OneHotEncoder(max_categories=3, sparse_output=False).fit(X)\n",
      ">>> ohe.infrequent_categories_\n",
      "[array(['a', 'd'], dtype=object)]\n",
      ">>> ohe.transform([[\"a\"], [\"b\"]])\n",
      "array([[0., 0., 1.],\n",
      "       [1., 0., 0.]])\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\franz\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages\\sklearn\\preprocessing\\_encoders.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "?OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['int', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_encode.py:173\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    171\u001b[0m uniques_set, missing_values \u001b[39m=\u001b[39m _extract_missing(uniques_set)\n\u001b[1;32m--> 173\u001b[0m uniques \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(uniques_set)\n\u001b[0;32m    174\u001b[0m uniques\u001b[39m.\u001b[39mextend(missing_values\u001b[39m.\u001b[39mto_list())\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\franz\\Documents\\GitHub\\EDEM2022\\3AnalisisYAprendizajeAutomatico\\ML_Intro\\one_hot_encoding.ipynb Cell 7\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franz/Documents/GitHub/EDEM2022/3AnalisisYAprendizajeAutomatico/ML_Intro/one_hot_encoding.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# One Hot Encoding\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franz/Documents/GitHub/EDEM2022/3AnalisisYAprendizajeAutomatico/ML_Intro/one_hot_encoding.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# use OneHotEncoder to encode categorical variables:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franz/Documents/GitHub/EDEM2022/3AnalisisYAprendizajeAutomatico/ML_Intro/one_hot_encoding.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dat_new \u001b[39m=\u001b[39m dat\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/franz/Documents/GitHub/EDEM2022/3AnalisisYAprendizajeAutomatico/ML_Intro/one_hot_encoding.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dat_new \u001b[39m=\u001b[39m OneHotEncoder()\u001b[39m.\u001b[39;49mfit_transform(dat_new)\u001b[39m.\u001b[39mtoarray()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/franz/Documents/GitHub/EDEM2022/3AnalisisYAprendizajeAutomatico/ML_Intro/one_hot_encoding.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dat_new\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_encoders.py:878\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse\n\u001b[0;32m    876\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_infrequent_enabled()\n\u001b[1;32m--> 878\u001b[0m fit_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    879\u001b[0m     X,\n\u001b[0;32m    880\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[0;32m    881\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    882\u001b[0m     return_counts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infrequent_enabled,\n\u001b[0;32m    883\u001b[0m )\n\u001b[0;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_infrequent_enabled:\n\u001b[0;32m    885\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_infrequent_category_mapping(\n\u001b[0;32m    886\u001b[0m         fit_results[\u001b[39m\"\u001b[39m\u001b[39mn_samples\u001b[39m\u001b[39m\"\u001b[39m], fit_results[\u001b[39m\"\u001b[39m\u001b[39mcategory_counts\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    887\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_encoders.py:93\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[1;34m(self, X, handle_unknown, force_all_finite, return_counts)\u001b[0m\n\u001b[0;32m     90\u001b[0m Xi \u001b[39m=\u001b[39m X_list[i]\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategories \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     result \u001b[39m=\u001b[39m _unique(Xi, return_counts\u001b[39m=\u001b[39;49mreturn_counts)\n\u001b[0;32m     94\u001b[0m     \u001b[39mif\u001b[39;00m return_counts:\n\u001b[0;32m     95\u001b[0m         cats, counts \u001b[39m=\u001b[39m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_encode.py:41\u001b[0m, in \u001b[0;36m_unique\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[39mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m _unique_python(\n\u001b[0;32m     42\u001b[0m         values, return_inverse\u001b[39m=\u001b[39;49mreturn_inverse, return_counts\u001b[39m=\u001b[39;49mreturn_counts\n\u001b[0;32m     43\u001b[0m     )\n\u001b[0;32m     44\u001b[0m \u001b[39m# numerical\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m _unique_np(\n\u001b[0;32m     46\u001b[0m     values, return_inverse\u001b[39m=\u001b[39mreturn_inverse, return_counts\u001b[39m=\u001b[39mreturn_counts\n\u001b[0;32m     47\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_encode.py:178\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     types \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(t\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(\u001b[39mtype\u001b[39m(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values))\n\u001b[1;32m--> 178\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    179\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEncoders require their input to be uniformly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstrings or numbers. Got \u001b[39m\u001b[39m{\u001b[39;00mtypes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m ret \u001b[39m=\u001b[39m (uniques,)\n\u001b[0;32m    184\u001b[0m \u001b[39mif\u001b[39;00m return_inverse:\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['int', 'str']"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "# use OneHotEncoder to encode categorical variables:\n",
    "ohe = OneHotEncoder(sparse= False, drop = 'first')\n",
    "ohe.fit(dat[['sales channel']])\n",
    "ohe.categories_\n",
    "\n",
    "dat_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
