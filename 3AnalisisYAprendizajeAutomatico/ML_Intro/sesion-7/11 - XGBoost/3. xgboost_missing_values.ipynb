{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de Missing Values con XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd \n",
    "import multiprocessing\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leamos el dataset a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32706, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset \n",
    "X = pd.read_csv(\"../datasets/dat_sanidad_raw.csv\", sep='|', decimal=',', encoding='latin-1')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset consta de:\n",
    "\n",
    "- 32706 **filas** o instancias\n",
    "- 10 **columnas** o variables.\n",
    "\n",
    "Veamos su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gravedad</th>\n",
       "      <th>pct_mortalidad_norma</th>\n",
       "      <th>edad_dias</th>\n",
       "      <th>numproc</th>\n",
       "      <th>potencial_ambul</th>\n",
       "      <th>proc</th>\n",
       "      <th>estancia_esperada</th>\n",
       "      <th>tipgrd</th>\n",
       "      <th>tiping</th>\n",
       "      <th>exitus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.408730</td>\n",
       "      <td>12596.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20973.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.278481</td>\n",
       "      <td>19611.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.150289</td>\n",
       "      <td>13583.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016573</td>\n",
       "      <td>18042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gravedad  pct_mortalidad_norma  edad_dias  numproc  potencial_ambul  proc  \\\n",
       "0         4              0.408730    12596.0       21                0     1   \n",
       "1         4                   NaN    20973.0       22                0     1   \n",
       "2         4              0.278481    19611.0       19                0     1   \n",
       "3         3              0.150289    13583.0       22                0     1   \n",
       "4         1              0.016573    18042.0        2                0     1   \n",
       "\n",
       "   estancia_esperada tipgrd  tiping  exitus  \n",
       "0                NaN      Q       1       0  \n",
       "1               99.0      Q       1       0  \n",
       "2                NaN      Q       1       0  \n",
       "3              100.0      Q       1       0  \n",
       "4                NaN      Q       1       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **gravedad**: Gravedad dentro del GRD. Valores de 1 a 4.\n",
    "\n",
    "- **pct_mortalidad_norma**: Tasa de mortalidad histórica para ese GRD.\n",
    "        \n",
    "- **edad_dias**: Edad en días del paciente.\n",
    "\n",
    "- **numproc**: Número de procedimientos que se han llevado a cabo al paciente a las 24 horas.\n",
    "    \n",
    "- **potencial_ambul**: Flag (valor 0 = no / 1 = sí) que indica si el caso se ha catalogado como potencialmente ambulatorio, es decir, no requiere ingreso.\n",
    "    \n",
    "- **proc**: Procedencia del paciente.\n",
    "\n",
    "- **estancia_esperada**: Número de días que se espera que el paciente esté ingresado en el hospital por este episodio asistencial.\n",
    "\n",
    "- **tipgrd**: GRD médico (M) o de quirófano (Q).\n",
    "    \n",
    "- **tiping**: Tipo de ingreso: Programado, urgente...\n",
    "    \n",
    "- **exitus**: 1 = El paciente falleció.\n",
    "\n",
    "De estas variables, fecing la usaremos para realizar el split en train/validacion/test, exitus es el target y las 10 variables restantes serán el input de nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, **tenemos missing values** en nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32706 entries, 0 to 32705\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   gravedad              32706 non-null  int64  \n",
      " 1   pct_mortalidad_norma  29399 non-null  float64\n",
      " 2   edad_dias             32232 non-null  float64\n",
      " 3   numproc               32706 non-null  int64  \n",
      " 4   potencial_ambul       32706 non-null  int64  \n",
      " 5   proc                  32706 non-null  int64  \n",
      " 6   estancia_esperada     5127 non-null   float64\n",
      " 7   tipgrd                32706 non-null  object \n",
      " 8   tiping                32706 non-null  int64  \n",
      " 9   exitus                32706 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos la técnica de one-hot encoding.\n",
    "\n",
    "<img src=\"../figures/oh.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionemos las variables categóricas en primer lugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = set(['gravedad', 'proc', 'tiping', 'tipgrd'])\n",
    "numerical_vars = set(X.columns) - categorical_vars\n",
    "categorical_vars = list(categorical_vars)\n",
    "numerical_vars = list(numerical_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiping', 'tipgrd', 'gravedad', 'proc']\n",
      "['edad_dias', 'potencial_ambul', 'estancia_esperada', 'pct_mortalidad_norma', 'exitus', 'numproc']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_vars)\n",
    "print(numerical_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos one hot encoding de las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe_fit = ohe.fit(X[categorical_vars])\n",
    "X_ohe = pd.DataFrame(ohe.fit_transform(X[categorical_vars]))\n",
    "X_ohe.columns = pd.DataFrame(ohe_fit.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos los datos iniciales y los que están con one hot encoding para ver la diferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tiping</th>\n",
       "      <th>tipgrd</th>\n",
       "      <th>gravedad</th>\n",
       "      <th>proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Q</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Q</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Q</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Q</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tiping tipgrd  gravedad  proc\n",
       "0       1      Q         4     1\n",
       "1       1      Q         4     1\n",
       "2       1      Q         4     1\n",
       "3       1      Q         3     1\n",
       "4       1      Q         1     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[categorical_vars].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(x0_1,)</th>\n",
       "      <th>(x0_2,)</th>\n",
       "      <th>(x0_3,)</th>\n",
       "      <th>(x1_M,)</th>\n",
       "      <th>(x1_Q,)</th>\n",
       "      <th>(x2_1,)</th>\n",
       "      <th>(x2_2,)</th>\n",
       "      <th>(x2_3,)</th>\n",
       "      <th>(x2_4,)</th>\n",
       "      <th>(x3_1,)</th>\n",
       "      <th>(x3_2,)</th>\n",
       "      <th>(x3_3,)</th>\n",
       "      <th>(x3_4,)</th>\n",
       "      <th>(x3_6,)</th>\n",
       "      <th>(x3_7,)</th>\n",
       "      <th>(x3_8,)</th>\n",
       "      <th>(x3_9,)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (x0_1,)  (x0_2,)  (x0_3,)  (x1_M,)  (x1_Q,)  (x2_1,)  (x2_2,)  (x2_3,)  \\\n",
       "0      1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "1      1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "3      1.0      0.0      0.0      0.0      1.0      0.0      0.0      1.0   \n",
       "4      1.0      0.0      0.0      0.0      1.0      1.0      0.0      0.0   \n",
       "\n",
       "   (x2_4,)  (x3_1,)  (x3_2,)  (x3_3,)  (x3_4,)  (x3_6,)  (x3_7,)  (x3_8,)  \\\n",
       "0      1.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      1.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      1.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   (x3_9,)  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a pegar las variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat((X_ohe, X[numerical_vars].reset_index()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipificar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a tipificar los datos, es decir, llevarlos a media 0 y desviación estándar 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figures/tipify.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['exitus']\n",
    "del X['exitus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    (x0_1,)  (x0_2,)   (x0_3,)   (x1_M,)   (x1_Q,)   (x2_1,)   (x2_2,)  \\\n",
      "0  0.589285  -0.5681 -0.118114 -1.554964  1.554964 -1.322185 -0.435743   \n",
      "1  0.589285  -0.5681 -0.118114 -1.554964  1.554964 -1.322185 -0.435743   \n",
      "2  0.589285  -0.5681 -0.118114 -1.554964  1.554964 -1.322185 -0.435743   \n",
      "3  0.589285  -0.5681 -0.118114 -1.554964  1.554964 -1.322185 -0.435743   \n",
      "4  0.589285  -0.5681 -0.118114 -1.554964  1.554964  0.756324 -0.435743   \n",
      "\n",
      "    (x2_3,)   (x2_4,)   (x3_1,)  ...   (x3_6,)   (x3_7,)   (x3_8,)   (x3_9,)  \\\n",
      "0 -0.417921  4.120705  0.589002  ... -0.118114 -0.009578 -0.134718 -0.090724   \n",
      "1 -0.417921  4.120705  0.589002  ... -0.118114 -0.009578 -0.134718 -0.090724   \n",
      "2 -0.417921  4.120705  0.589002  ... -0.118114 -0.009578 -0.134718 -0.090724   \n",
      "3  2.392797 -0.242677  0.589002  ... -0.118114 -0.009578 -0.134718 -0.090724   \n",
      "4 -0.417921 -0.242677  0.589002  ... -0.118114 -0.009578 -0.134718 -0.090724   \n",
      "\n",
      "      index  edad_dias  potencial_ambul  estancia_esperada  \\\n",
      "0 -1.731998  -0.712991        -0.258527                NaN   \n",
      "1 -1.731892   0.186339        -0.258527          15.495328   \n",
      "2 -1.731786   0.040118        -0.258527                NaN   \n",
      "3 -1.731680  -0.607030        -0.258527          15.659833   \n",
      "4 -1.731574  -0.128325        -0.258527                NaN   \n",
      "\n",
      "   pct_mortalidad_norma   numproc  \n",
      "0              5.691805  6.002393  \n",
      "1                   NaN  6.357038  \n",
      "2              3.733432  5.293102  \n",
      "3              1.805990  6.357038  \n",
      "4             -0.204504 -0.735868  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "X_scale = pd.DataFrame(scale(X))\n",
    "X_scale.columns = X.columns\n",
    "X = X_scale\n",
    "X.columns = X_scale.columns\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split en Train/Validación/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos a modo de ejemplo los ratios habitualmente recomendados:\n",
    "\n",
    "• Train: 70%.\n",
    "\n",
    "• Validación: 15%.\n",
    "\n",
    "• Test: 15%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_values = [0.7, 0.15, 0.15];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los conjuntos de train, validacion y test con el tamaño seleccionado pero respetando el eje temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensiones de los conjuntos de train y test\n",
    "n_train = int(X.shape[0] * perc_values[0])\n",
    "n_val = int(X.shape[0] * perc_values[1])\n",
    "n_test = int(X.shape[0] * perc_values[2])\n",
    "\n",
    "# selección del conjunto de train\n",
    "X_train = X.iloc[:n_train]\n",
    "y_train = y.iloc[:n_train]\n",
    "\n",
    "# selección del conjunto de validación\n",
    "X_val = X.iloc[(n_train):(n_train+n_val)]\n",
    "y_val = y.iloc[(n_train):(n_train+n_val)]\n",
    "\n",
    "# selección del conjunto de test\n",
    "X_test = X.iloc[(n_train+n_val):]\n",
    "y_test = y.iloc[(n_train+n_val):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos el tamaño de los 3 subdatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size = (22894, 23)\n",
      "Train target size = (22894,)\n",
      "Validation data size = (4905, 23)\n",
      "Validation target size = (4905,)\n",
      "Test data size = (4907, 23)\n",
      "Test target size = (4907,)\n"
     ]
    }
   ],
   "source": [
    "print('Train data size = ' + str(X_train.shape))\n",
    "print('Train target size = ' + str(y_train.shape))\n",
    "print('Validation data size = ' + str(X_val.shape))\n",
    "print('Validation target size = ' + str(y_val.shape))\n",
    "print('Test data size = ' + str(X_test.shape))\n",
    "print('Test target size = ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Importar modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC as model_constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Importar métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score as metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Definir el método.\n",
    "\n",
    "Vamos a entrenar un modelo con parámetros por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_constructor(random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Llamar al método fit para entrenar el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7ec66d62bed2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(X_train, \n\u001b[0m\u001b[0;32m      2\u001b[0m           np.array(y_train))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             X, y = self._validate_data(X, y, dtype=np.float64,\n\u001b[0m\u001b[0;32m    170\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m                                        accept_large_sparse=False)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          np.array(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos en las clases, la mayoría de modelos **no aceptan missing values**. Sin embargo, los **modelos basados en árboles** son una **excepción**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## XGBoost\n",
    "\n",
    "Vamos a aplicar ahora un modelo de XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Importar modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier as model_constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Definir el método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_constructor(random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Llamar al método fit para entrenar el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.90469\n",
      "[1]\tvalidation_0-auc:0.90519\n",
      "[2]\tvalidation_0-auc:0.91386\n",
      "[3]\tvalidation_0-auc:0.91716\n",
      "[4]\tvalidation_0-auc:0.91539\n",
      "[5]\tvalidation_0-auc:0.91755\n",
      "[6]\tvalidation_0-auc:0.91752\n",
      "[7]\tvalidation_0-auc:0.91800\n",
      "[8]\tvalidation_0-auc:0.92148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jesus\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jesus\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\tvalidation_0-auc:0.92331\n",
      "[10]\tvalidation_0-auc:0.92184\n",
      "[11]\tvalidation_0-auc:0.92404\n",
      "[12]\tvalidation_0-auc:0.92470\n",
      "[13]\tvalidation_0-auc:0.92558\n",
      "[14]\tvalidation_0-auc:0.92564\n",
      "[15]\tvalidation_0-auc:0.92563\n",
      "[16]\tvalidation_0-auc:0.92711\n",
      "[17]\tvalidation_0-auc:0.92477\n",
      "[18]\tvalidation_0-auc:0.92508\n",
      "[19]\tvalidation_0-auc:0.92623\n",
      "[20]\tvalidation_0-auc:0.92679\n",
      "[21]\tvalidation_0-auc:0.92693\n",
      "[22]\tvalidation_0-auc:0.92383\n",
      "[23]\tvalidation_0-auc:0.92419\n",
      "[24]\tvalidation_0-auc:0.92401\n",
      "[25]\tvalidation_0-auc:0.92464\n",
      "[26]\tvalidation_0-auc:0.92420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          np.array(y_train), \n",
    "          eval_metric = \"auc\", \n",
    "          eval_set=[(X_val, y_val)],\n",
    "          early_stopping_rounds = 10,\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Funciona sin hacer nada!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Llamar al método predict para generar las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_p = model.predict_proba(X_train)\n",
    "pred_val_p = model.predict_proba(X_val)\n",
    "pred_test_p = model.predict_proba(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Calcular métrica usando las predicciones obtenidas en el paso anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas de evaluación\n",
    "auc_train = metric(y_train, pred_train_p[:,1]);\n",
    "auc_val = metric(y_val, pred_val_p[:,1]);\n",
    "auc_test = metric(y_test, pred_test_p[:,1]);\n",
    "results = pd.DataFrame()\n",
    "results = results.append(pd.DataFrame(data={'model':['XGBoost (Default)'],'auc_train':[auc_train],'auc_val':[auc_val],'auc_test':[auc_test]}, columns=['model',  'auc_train','auc_val', 'auc_test']), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_val</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost (Default)</td>\n",
       "      <td>0.965539</td>\n",
       "      <td>0.927106</td>\n",
       "      <td>0.925819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  auc_train   auc_val  auc_test\n",
       "0  XGBoost (Default)   0.965539  0.927106  0.925819"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparemos su performance con respecto a un método básico como rellenar con la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_vars = list(set(numerical_vars) - set(['exitus']))\n",
    "means = X_train[numerical_vars].apply(lambda x: np.mean(x)).to_dict()\n",
    "X_train = X_train.fillna(value = means, axis = 0)\n",
    "X_val = X_val.fillna(value = means, axis = 0)\n",
    "X_test = X_test.fillna(value = means, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Definir el método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_constructor(random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Llamar al método fit para entrenar el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.90608\n",
      "[1]\tvalidation_0-auc:0.90428\n",
      "[2]\tvalidation_0-auc:0.90338\n",
      "[3]\tvalidation_0-auc:0.91100\n",
      "[4]\tvalidation_0-auc:0.91124\n",
      "[5]\tvalidation_0-auc:0.91581\n",
      "[6]\tvalidation_0-auc:0.91632\n",
      "[7]\tvalidation_0-auc:0.91766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jesus\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jesus\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\tvalidation_0-auc:0.91728\n",
      "[9]\tvalidation_0-auc:0.92208\n",
      "[10]\tvalidation_0-auc:0.92358\n",
      "[11]\tvalidation_0-auc:0.92412\n",
      "[12]\tvalidation_0-auc:0.92524\n",
      "[13]\tvalidation_0-auc:0.92525\n",
      "[14]\tvalidation_0-auc:0.92553\n",
      "[15]\tvalidation_0-auc:0.92509\n",
      "[16]\tvalidation_0-auc:0.92540\n",
      "[17]\tvalidation_0-auc:0.92781\n",
      "[18]\tvalidation_0-auc:0.92878\n",
      "[19]\tvalidation_0-auc:0.92342\n",
      "[20]\tvalidation_0-auc:0.92365\n",
      "[21]\tvalidation_0-auc:0.92332\n",
      "[22]\tvalidation_0-auc:0.92365\n",
      "[23]\tvalidation_0-auc:0.92334\n",
      "[24]\tvalidation_0-auc:0.92336\n",
      "[25]\tvalidation_0-auc:0.92330\n",
      "[26]\tvalidation_0-auc:0.92367\n",
      "[27]\tvalidation_0-auc:0.92446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          np.array(y_train), \n",
    "          eval_metric = \"auc\", \n",
    "          eval_set=[(X_val, y_val)],\n",
    "          early_stopping_rounds = 10,\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Llamar al método predict para generar las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_p = model.predict_proba(X_train)\n",
    "pred_val_p = model.predict_proba(X_val)\n",
    "pred_test_p = model.predict_proba(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Calcular métrica usando las predicciones obtenidas en el paso anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas de evaluación\n",
    "auc_train = metric(y_train, pred_train_p[:,1]);\n",
    "auc_val = metric(y_val, pred_val_p[:,1]);\n",
    "auc_test = metric(y_test, pred_test_p[:,1]);\n",
    "results = results.append(pd.DataFrame(data={'model':['XGBoost fill missing'],'auc_train':[auc_train],'auc_val':[auc_val],'auc_test':[auc_test]}, columns=['model',  'auc_train','auc_val', 'auc_test']), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>auc_val</th>\n",
       "      <th>auc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost (Default)</td>\n",
       "      <td>0.965539</td>\n",
       "      <td>0.927106</td>\n",
       "      <td>0.925819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost fill missing</td>\n",
       "      <td>0.964769</td>\n",
       "      <td>0.928780</td>\n",
       "      <td>0.921408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  auc_train   auc_val  auc_test\n",
       "0     XGBoost (Default)   0.965539  0.927106  0.925819\n",
       "1  XGBoost fill missing   0.964769  0.928780  0.921408"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
